{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherry975/CSC-791-Project/blob/master/embedding_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-ZhQ0tHbAQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "8bb815f8-1337-4f1c-fdfb-e7a46657ee28"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# !ls \"/content/drive/My Drive/\"\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/CSC791-NLP/791 NLP project/791_project_repo\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "import sys\n",
        "import traceback\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import datetime\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "\n",
        "def print_time(*args):\n",
        "    text = \"\"\n",
        "    for arg in args:\n",
        "        text += arg\n",
        "    print(\"[\",datetime.datetime.now(),\"]\", text)\n",
        "\n",
        "\n",
        "def pickle_save(filename, data2pkl):\n",
        "    fileObject = open(filename,'wb') \n",
        "    pickle.dump(data2pkl,fileObject)\n",
        "    fileObject.close()\n",
        "\n",
        "        \n",
        "def pickle_load(filename):\n",
        "    fileObject = open(filename,'rb') \n",
        "    data_unpkl = pickle.load(fileObject)\n",
        "    fileObject.close()\n",
        "    return data_unpkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIit8IR1bTo1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "7463c051-a570-431b-833e-8f03a6909275"
      },
      "source": [
        "# get embeddings from trained SDAE\n",
        "# https://github.com/fh295/SentenceRepresentation/pull/5\n",
        "\n",
        "import theano\n",
        "import theano.tensor as tensor\n",
        "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
        "import pickle as pkl\n",
        "import numpy\n",
        "import copy\n",
        "import os\n",
        "import pdb\n",
        "from scipy import optimize, stats\n",
        "from collections import OrderedDict\n",
        "# from sklearn.cross_validation import KFold\n",
        "\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "profile = False\n",
        "\n",
        "# push parameters to Theano shared variables\n",
        "def zipp(params, tparams):\n",
        "    for kk, vv in params.items():\n",
        "        tparams[kk].set_value(vv)\n",
        "\n",
        "\n",
        "# pull parameters from Theano shared variables\n",
        "def unzip(zipped):\n",
        "    new_params = OrderedDict()\n",
        "    for kk, vv in zipped.items():\n",
        "        new_params[kk] = vv.get_value()\n",
        "    return new_params\n",
        "\n",
        "\n",
        "# get the list of parameters: Note that tparams must be OrderedDict\n",
        "def itemlist(tparams):\n",
        "    return [vv for kk, vv in tparams.items()]\n",
        "\n",
        "\n",
        "# dropout\n",
        "def dropout_layer(state_before, use_noise, trng):\n",
        "    proj = tensor.switch(use_noise,\n",
        "                         state_before * trng.binomial(state_before.shape, p=0.5, n=1, dtype=state_before.dtype),\n",
        "                         state_before * 0.5)\n",
        "    return proj\n",
        "\n",
        "\n",
        "# make prefix-appended name\n",
        "def _p(pp, name):\n",
        "    return '%s_%s' % (pp, name)\n",
        "\n",
        "\n",
        "# initialize Theano shared variables according to the initial parameters\n",
        "def init_tparams(params):\n",
        "    tparams = OrderedDict()\n",
        "    for kk, pp in params.items():\n",
        "        tparams[kk] = theano.shared(params[kk], name=kk)\n",
        "    return tparams\n",
        "\n",
        "\n",
        "# load parameters\n",
        "def load_params(path, params):\n",
        "    pp = numpy.load(path)\n",
        "    # print(\"pp: \")\n",
        "    # print(pp)\n",
        "    # for p in pp:\n",
        "    #     print(p)\n",
        "    for kk, vv in params.items():\n",
        "        if kk not in pp:\n",
        "            raise Warning('%s is not in the archive' % kk)\n",
        "        params[kk] = pp[kk]\n",
        "    # print(\"end pp.\")\n",
        "    return params\n",
        "\n",
        "\n",
        "# layers: 'name': ('parameter initializer', 'feedforward')\n",
        "layers = {'ff': ('param_init_fflayer', 'fflayer'),\n",
        "          'gru': ('param_init_gru', 'gru_layer'),\n",
        "          'gru_cond': ('param_init_gru_cond', 'gru_cond_layer'),\n",
        "          }\n",
        "\n",
        "\n",
        "def get_layer(name):\n",
        "    fns = layers[name]\n",
        "    return (eval(fns[0]), eval(fns[1]))\n",
        "\n",
        "\n",
        "# some utilities\n",
        "def ortho_weight(ndim):\n",
        "    W = numpy.random.randn(ndim, ndim)\n",
        "    u, s, v = numpy.linalg.svd(W)\n",
        "    return u.astype('float32')\n",
        "\n",
        "\n",
        "def norm_weight(nin, nout=None, scale=0.01, orth=True):\n",
        "    if nout == None:\n",
        "        nout = nin\n",
        "    if nout == nin and orth:\n",
        "        W = ortho_weight(nin)\n",
        "    else:\n",
        "        W = scale * numpy.random.randn(nin, nout)\n",
        "    return W.astype('float32')\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return tensor.tanh(x)\n",
        "\n",
        "\n",
        "def rectifier(x):\n",
        "    return tensor.maximum(0., x)\n",
        "\n",
        "\n",
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "\n",
        "# feedforward layer: affine transformation + point-wise nonlinearity\n",
        "def param_init_fflayer(options, params, prefix='ff', nin=None, nout=None, orth=True):\n",
        "    if nin == None:\n",
        "        nin = options['dim_proj']\n",
        "    if nout == None:\n",
        "        nout = options['dim_proj']\n",
        "    params[_p(prefix, 'W')] = norm_weight(nin, nout, scale=0.01, orth=orth)\n",
        "    params[_p(prefix, 'b')] = numpy.zeros((nout,)).astype('float32')\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "def fflayer(tparams, state_below, options, prefix='rconv', activ='lambda x: tensor.tanh(x)', **kwargs):\n",
        "    return eval(activ)(tensor.dot(state_below, tparams[_p(prefix, 'W')]) + tparams[_p(prefix, 'b')])\n",
        "\n",
        "\n",
        "# GRU layer\n",
        "def param_init_gru(options, params, prefix='gru', nin=None, dim=None, hiero=False):\n",
        "    if nin == None:\n",
        "        nin = options['dim_proj']\n",
        "    if dim == None:\n",
        "        dim = options['dim_proj']\n",
        "    if not hiero:\n",
        "        W = numpy.concatenate([norm_weight(nin, dim),\n",
        "                               norm_weight(nin, dim)], axis=1)\n",
        "        params[_p(prefix, 'W')] = W\n",
        "        params[_p(prefix, 'b')] = numpy.zeros((2 * dim,)).astype('float32')\n",
        "    U = numpy.concatenate([ortho_weight(dim),\n",
        "                           ortho_weight(dim)], axis=1)\n",
        "    params[_p(prefix, 'U')] = U\n",
        "\n",
        "    Wx = norm_weight(nin, dim)\n",
        "    params[_p(prefix, 'Wx')] = Wx\n",
        "    Ux = ortho_weight(dim)\n",
        "    params[_p(prefix, 'Ux')] = Ux\n",
        "    params[_p(prefix, 'bx')] = numpy.zeros((dim,)).astype('float32')\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "def gru_layer(tparams, state_below, options, prefix='gru', mask=None, **kwargs):\n",
        "    nsteps = state_below.shape[0]\n",
        "    if state_below.ndim == 3:\n",
        "        n_samples = state_below.shape[1]\n",
        "    else:\n",
        "        n_samples = 1\n",
        "\n",
        "    dim = tparams[_p(prefix, 'Ux')].shape[1]\n",
        "\n",
        "    if mask == None:\n",
        "        mask = tensor.alloc(1., state_below.shape[0], 1)\n",
        "\n",
        "    def _slice(_x, n, dim):\n",
        "        if _x.ndim == 3:\n",
        "            return _x[:, :, n * dim:(n + 1) * dim]\n",
        "        return _x[:, n * dim:(n + 1) * dim]\n",
        "\n",
        "    state_below_ = tensor.dot(state_below, tparams[_p(prefix, 'W')]) + tparams[_p(prefix, 'b')]\n",
        "    state_belowx = tensor.dot(state_below, tparams[_p(prefix, 'Wx')]) + tparams[_p(prefix, 'bx')]\n",
        "    U = tparams[_p(prefix, 'U')]\n",
        "    Ux = tparams[_p(prefix, 'Ux')]\n",
        "\n",
        "    def _step_slice(m_, x_, xx_, h_, U, Ux):\n",
        "        preact = tensor.dot(h_, U)\n",
        "        preact += x_\n",
        "\n",
        "        r = tensor.nnet.sigmoid(_slice(preact, 0, dim))\n",
        "        u = tensor.nnet.sigmoid(_slice(preact, 1, dim))\n",
        "\n",
        "        preactx = tensor.dot(h_, Ux)\n",
        "        preactx = preactx * r\n",
        "        preactx = preactx + xx_\n",
        "\n",
        "        h = tensor.tanh(preactx)\n",
        "\n",
        "        h = u * h_ + (1. - u) * h\n",
        "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
        "\n",
        "        return h  # , r, u, preact, preactx\n",
        "\n",
        "    seqs = [mask, state_below_, state_belowx]\n",
        "    _step = _step_slice\n",
        "\n",
        "    rval, updates = theano.scan(_step,\n",
        "                                sequences=seqs,\n",
        "                                outputs_info=[tensor.alloc(0., n_samples, dim)],\n",
        "                                # None, None, None, None],\n",
        "                                non_sequences=[tparams[_p(prefix, 'U')],\n",
        "                                               tparams[_p(prefix, 'Ux')]],\n",
        "                                name=_p(prefix, '_layers'),\n",
        "                                n_steps=nsteps,\n",
        "                                profile=profile,\n",
        "                                strict=True)\n",
        "    rval = [rval]\n",
        "    return rval\n",
        "\n",
        "\n",
        "# Conditional GRU layer without Attention\n",
        "def param_init_gru_cond(options, params, prefix='gru_cond', nin=None, dim=None, dimctx=None):\n",
        "    if nin == None:\n",
        "        nin = options['dim']\n",
        "    if dim == None:\n",
        "        dim = options['dim']\n",
        "    if dimctx == None:\n",
        "        dimctx = options['dim']\n",
        "\n",
        "    params = param_init_gru(options, params, prefix, nin=nin, dim=dim)\n",
        "\n",
        "    # context to LSTM\n",
        "    Wc = norm_weight(dimctx, dim * 2)\n",
        "    params[_p(prefix, 'Wc')] = Wc\n",
        "\n",
        "    Wcx = norm_weight(dimctx, dim)\n",
        "    params[_p(prefix, 'Wcx')] = Wcx\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "def gru_cond_layer(tparams, state_below, options, prefix='gru',\n",
        "                   mask=None, context=None, one_step=False,\n",
        "                   init_memory=None, init_state=None,\n",
        "                   context_mask=None,\n",
        "                   **kwargs):\n",
        "    assert context, 'Context must be provided'\n",
        "\n",
        "    if one_step:\n",
        "        assert init_state, 'previous state must be provided'\n",
        "\n",
        "    nsteps = state_below.shape[0]\n",
        "    if state_below.ndim == 3:\n",
        "        n_samples = state_below.shape[1]\n",
        "    else:\n",
        "        n_samples = 1\n",
        "\n",
        "    # mask\n",
        "    if mask == None:\n",
        "        mask = tensor.alloc(1., state_below.shape[0], 1)\n",
        "\n",
        "    dim = tparams[_p(prefix, 'Ux')].shape[1]\n",
        "\n",
        "    # initial/previous state\n",
        "    if init_state == None:\n",
        "        init_state = tensor.alloc(0., n_samples, dim)\n",
        "\n",
        "    # projected context\n",
        "    assert context.ndim == 2, 'Context must be 2-d: #sample x dim'\n",
        "    pctx_ = tensor.dot(context, tparams[_p(prefix, 'Wc')])\n",
        "    pctxx_ = tensor.dot(context, tparams[_p(prefix, 'Wcx')])\n",
        "\n",
        "    def _slice(_x, n, dim):\n",
        "        if _x.ndim == 3:\n",
        "            return _x[:, :, n * dim:(n + 1) * dim]\n",
        "        return _x[:, n * dim:(n + 1) * dim]\n",
        "\n",
        "    # projected x\n",
        "    state_belowx = tensor.dot(state_below, tparams[_p(prefix, 'Wx')]) + tparams[_p(prefix, 'bx')]\n",
        "    state_below_ = tensor.dot(state_below, tparams[_p(prefix, 'W')]) + tparams[_p(prefix, 'b')]\n",
        "\n",
        "    def _step_slice(m_, x_, xx_, h_, pctx_, pctxx_, U, Ux):\n",
        "        preact = tensor.dot(h_, U)\n",
        "        preact += x_\n",
        "        preact += pctx_\n",
        "        preact = tensor.nnet.sigmoid(preact)\n",
        "\n",
        "        r = _slice(preact, 0, dim)\n",
        "        u = _slice(preact, 1, dim)\n",
        "\n",
        "        preactx = tensor.dot(h_, Ux)\n",
        "        preactx *= r\n",
        "        preactx += xx_\n",
        "        preactx += pctxx_\n",
        "\n",
        "        h = tensor.tanh(preactx)\n",
        "\n",
        "        h = u * h_ + (1. - u) * h\n",
        "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
        "\n",
        "        return h\n",
        "\n",
        "    seqs = [mask, state_below_, state_belowx]\n",
        "    _step = _step_slice\n",
        "\n",
        "    shared_vars = [tparams[_p(prefix, 'U')],\n",
        "                   tparams[_p(prefix, 'Ux')]]\n",
        "\n",
        "    if one_step:\n",
        "        rval = _step(*(seqs + [init_state, pctx_, pctxx_] + shared_vars))\n",
        "    else:\n",
        "        rval, updates = theano.scan(_step,\n",
        "                                    sequences=seqs,\n",
        "                                    outputs_info=[init_state],\n",
        "                                    non_sequences=[pctx_,\n",
        "                                                   pctxx_] + shared_vars,\n",
        "                                    name=_p(prefix, '_layers'),\n",
        "                                    n_steps=nsteps,\n",
        "                                    profile=profile,\n",
        "                                    strict=True)\n",
        "    return rval\n",
        "\n",
        "\n",
        "# initialize all parameters\n",
        "def init_params(options):\n",
        "    params = OrderedDict()\n",
        "    # embedding: shared\n",
        "    params['Wemb'] = norm_weight(options['n_words'], options['dim_word'])\n",
        "    # encoder\n",
        "    params = get_layer(options['encoder'])[0](options, params, prefix='encoder',\n",
        "                                              nin=options['dim_word'],\n",
        "                                              dim=options['dim'])\n",
        "    init_state = get_layer('ff')[0](options, params, prefix='ff_state',\n",
        "                                    nin=options['dim'], nout=options['dim'])\n",
        "    # decoder\n",
        "    params = get_layer(options['decoder'])[0](options, params, prefix='decoder',\n",
        "                                              nin=options['dim_word'],\n",
        "                                              dim=options['dim'],\n",
        "                                              dimctx=options['dim'])\n",
        "    # readout\n",
        "    params = get_layer('ff')[0](options, params, prefix='ff_logit',\n",
        "                                nin=options['dim'], nout=options['n_words'])\n",
        "\n",
        "    return params\n",
        "\n",
        "# build a training model\n",
        "def build_model(tparams, options):\n",
        "    trng = RandomStreams(1234)\n",
        "    use_noise = theano.shared(numpy.float32(0.))\n",
        "\n",
        "    # clean string: #words x #samples\n",
        "    x = tensor.matrix('x', dtype='int64')\n",
        "    x_mask = tensor.matrix('x_mask', dtype='float32')\n",
        "    # noisy string: #words x #samples\n",
        "    if options['use_preemb']:\n",
        "        x_noise = tensor.tensor3('x_noise', dtype='float32')\n",
        "    else:\n",
        "        x_noise = tensor.matrix('x_noise', dtype='int64')\n",
        "    xn_mask = tensor.matrix('x_noise_mask', dtype='float32')\n",
        "\n",
        "    n_timesteps = x_noise.shape[0]\n",
        "    n_samples = x_noise.shape[1]\n",
        "\n",
        "    # word embedding (source)\n",
        "    if options['use_preemb']:\n",
        "        emb = x_noise\n",
        "    else:\n",
        "        emb = tparams['Wemb'][x_noise.flatten()].reshape([n_timesteps, n_samples, options['dim_word']])\n",
        "    # encoder\n",
        "    proj = get_layer(options['encoder'])[1](tparams, emb, options,\n",
        "                                            prefix='encoder',\n",
        "                                            mask=xn_mask)\n",
        "    ctx = proj[0][-1]  # the last hidden state is the context\n",
        "    init_state = get_layer('ff')[1](tparams, ctx, options,\n",
        "                                    prefix='ff_state', activ='tanh')\n",
        "\n",
        "    n_timesteps = x.shape[0]\n",
        "    n_samples = x.shape[1]\n",
        "\n",
        "    # word embedding (target)\n",
        "    emb = tparams['Wemb'][x.flatten()].reshape([n_timesteps, n_samples, options['dim_word']])\n",
        "    emb_shifted = tensor.zeros_like(emb)\n",
        "    emb_shifted = tensor.set_subtensor(emb_shifted[1:], emb[:-1])\n",
        "    emb = emb_shifted\n",
        "    # decoder\n",
        "    proj = get_layer(options['decoder'])[1](tparams, emb, options,\n",
        "                                            prefix='decoder',\n",
        "                                            mask=x_mask, context=ctx,\n",
        "                                            one_step=False,\n",
        "                                            init_state=init_state)\n",
        "    proj_h = proj\n",
        "    # compute word probabilities\n",
        "    logit = get_layer('ff')[1](tparams, proj_h, options, prefix='ff_logit', activ='linear')\n",
        "    logit_shp = logit.shape\n",
        "    probs = tensor.nnet.softmax(logit.reshape([logit_shp[0] * logit_shp[1], logit_shp[2]]))\n",
        "    # cost\n",
        "    x_flat = x.flatten()\n",
        "    x_flat_idx = tensor.arange(x_flat.shape[0]) * options['n_words'] + x_flat\n",
        "    cost = -tensor.log(probs.flatten()[x_flat_idx] + 1e-8)\n",
        "    cost = cost.reshape([x.shape[0], x.shape[1]])\n",
        "    cost = (cost * x_mask).sum(0)\n",
        "    cost = cost.mean()\n",
        "\n",
        "    return trng, use_noise, x, x_mask, x_noise, xn_mask, ctx, cost\n",
        "\n",
        "\n",
        "# build a sampler\n",
        "def build_sampler(tparams, options, trng):\n",
        "    if options['use_preemb']:\n",
        "        x = tensor.tensor3('x', dtype='float32')\n",
        "    else:\n",
        "        x = tensor.matrix('x', dtype='int64')\n",
        "    xr = x[::-1]\n",
        "    n_timesteps = x.shape[0]\n",
        "    n_samples = x.shape[1]\n",
        "\n",
        "    # word embedding (source)\n",
        "    if options['use_preemb']:\n",
        "        emb = x\n",
        "    else:\n",
        "        emb = tparams['Wemb'][x.flatten()].reshape([n_timesteps, n_samples, options['dim_word']])\n",
        "    # encoder\n",
        "    proj = get_layer(options['encoder'])[1](tparams, emb, options, prefix='encoder')\n",
        "\n",
        "    ctx = proj[0][-1]\n",
        "    ctx_mean = ctx\n",
        "\n",
        "    init_state = get_layer('ff')[1](tparams, ctx_mean, options, prefix='ff_state', activ='tanh')\n",
        "\n",
        "    print('Building f_init...',\n",
        "          outs=[init_state, ctx])\n",
        "    f_init = theano.function([x], outs, name='f_init', profile=profile)\n",
        "    print('Done')\n",
        "\n",
        "    # x: 1 x 1\n",
        "    y = tensor.vector('y_sampler', dtype='int64')\n",
        "    init_state = tensor.matrix('init_state', dtype='float32')\n",
        "    ctx = tensor.matrix('ctx', dtype='float32')\n",
        "\n",
        "    # if it's the first word, emb should be all zero\n",
        "    emb = tensor.switch(y[:, None] < 0,\n",
        "                        tensor.alloc(0., 1, tparams['Wemb'].shape[1]),\n",
        "                        tparams['Wemb'][y])\n",
        "    proj = get_layer(options['decoder'])[1](tparams, emb, options,\n",
        "                                            prefix='decoder',\n",
        "                                            mask=None, context=ctx,\n",
        "                                            one_step=True,\n",
        "                                            init_state=init_state)\n",
        "    next_state = proj\n",
        "\n",
        "    logit = get_layer('ff')[1](tparams, proj, options, prefix='ff_logit', activ='linear')\n",
        "    logit_shp = logit.shape\n",
        "    next_probs = tensor.nnet.softmax(logit)\n",
        "    next_sample = trng.multinomial(pvals=next_probs).argmax(1)\n",
        "\n",
        "    # next word probability\n",
        "    print('Building f_next..', )\n",
        "    inps = [y, ctx, init_state]\n",
        "    outs = [next_probs, next_sample, next_state]\n",
        "    f_next = theano.function(inps, outs, name='f_next', profile=profile)\n",
        "    print('Done')\n",
        "\n",
        "    return f_init, f_next\n",
        "\n",
        "\n",
        "# generate sample\n",
        "def gen_sample(tparams, f_init, f_next, x, options, trng=None, k=1, maxlen=30,\n",
        "               stochastic=True, argmax=False):\n",
        "    if k > 1:\n",
        "        assert not stochastic, 'Beam search does not support stochastic sampling'\n",
        "\n",
        "    sample = []\n",
        "    sample_score = []\n",
        "    if stochastic:\n",
        "        sample_score = 0\n",
        "\n",
        "    live_k = 1\n",
        "    dead_k = 0\n",
        "\n",
        "    hyp_samples = [[]] * live_k\n",
        "    hyp_scores = numpy.zeros(live_k).astype('float32')\n",
        "    hyp_states = []\n",
        "\n",
        "    ret = f_init(x)\n",
        "    next_state, ctx0 = ret[0], ret[1]\n",
        "    next_w = -1 * numpy.ones((1,)).astype('int64')\n",
        "\n",
        "    for ii in range(maxlen):\n",
        "        ctx = numpy.tile(ctx0, [live_k, 1])\n",
        "        inps = [next_w, ctx, next_state]\n",
        "        ret = f_next(*inps)\n",
        "        next_p, next_w, next_state = ret[0], ret[1], ret[2]\n",
        "\n",
        "        if stochastic:\n",
        "            if argmax:\n",
        "                nw = next_p[0].argmax()\n",
        "            else:\n",
        "                nw = next_w[0]\n",
        "            sample.append(nw)\n",
        "            sample_score += next_p[0, nw]\n",
        "            if nw == 0:\n",
        "                break\n",
        "        else:\n",
        "            cand_scores = hyp_scores[:, None] - numpy.log(next_p)\n",
        "            cand_flat = cand_scores.flatten()\n",
        "            ranks_flat = cand_flat.argsort()[:(k - dead_k)]\n",
        "\n",
        "            voc_size = next_p.shape[1]\n",
        "            trans_indices = ranks_flat / voc_size\n",
        "            word_indices = ranks_flat % voc_size\n",
        "            costs = cand_flat[ranks_flat]\n",
        "\n",
        "            new_hyp_samples = []\n",
        "            new_hyp_scores = numpy.zeros(k - dead_k).astype('float32')\n",
        "            new_hyp_states = []\n",
        "\n",
        "            for idx, [ti, wi] in enumerate(zip(trans_indices, word_indices)):\n",
        "                new_hyp_samples.append(hyp_samples[ti] + [wi])\n",
        "                new_hyp_scores[idx] = copy.copy(costs[ti])\n",
        "                new_hyp_states.append(copy.copy(next_state[ti]))\n",
        "\n",
        "            # check the finished samples\n",
        "            new_live_k = 0\n",
        "            hyp_samples = []\n",
        "            hyp_scores = []\n",
        "            hyp_states = []\n",
        "\n",
        "            for idx in range(len(new_hyp_samples)):\n",
        "                if new_hyp_samples[idx][-1] == 0:\n",
        "                    sample.append(new_hyp_samples[idx])\n",
        "                    sample_score.append(new_hyp_scores[idx])\n",
        "                    dead_k += 1\n",
        "                else:\n",
        "                    new_live_k += 1\n",
        "                    hyp_samples.append(new_hyp_samples[idx])\n",
        "                    hyp_scores.append(new_hyp_scores[idx])\n",
        "                    hyp_states.append(new_hyp_states[idx])\n",
        "            hyp_scores = numpy.array(hyp_scores)\n",
        "            live_k = new_live_k\n",
        "\n",
        "            if new_live_k < 1:\n",
        "                break\n",
        "            if dead_k >= k:\n",
        "                break\n",
        "\n",
        "            next_w = numpy.array([w[-1] for w in hyp_samples])\n",
        "            next_state = numpy.array(hyp_states)\n",
        "\n",
        "    if not stochastic:\n",
        "        # dump every remaining one\n",
        "        if live_k > 0:\n",
        "            for idx in range(live_k):\n",
        "                sample.append(hyp_samples[idx])\n",
        "                sample_score.append(hyp_scores[idx])\n",
        "\n",
        "    return sample, sample_score\n",
        "\n",
        "\n",
        "def recon_err(f_recon_err, prepare_data, data, iterator,\n",
        "              corrupt=None, verbose=False,\n",
        "              use_preemb=False, wv_emb=None):\n",
        "    n_samples = len(data[0])\n",
        "    probs = numpy.zeros((n_samples, 1)).astype('float32')\n",
        "\n",
        "    n_done = 0\n",
        "\n",
        "    for _, valid_index in iterator:\n",
        "        x, mask = prepare_data([valid[0][t] for t in valid_index])\n",
        "        if corrupt is not None:\n",
        "            x_noise = corrupt(x)\n",
        "        else:\n",
        "            x_noise = copy.copy(x)\n",
        "        if use_preemb:\n",
        "            shp = x_noise.shape\n",
        "            x_noise = wv_embs[x_noise.flatten()].reshape([shp[0], shp[1], wv_embs.shape[1]])\n",
        "        pred_probs = f_recon_err(x, x_noise, mask)\n",
        "        probs[valid_index] = pred_probs[:, None]\n",
        "\n",
        "        n_done += len(valid_index)\n",
        "        if verbose:\n",
        "            print('%d/%d samples computed' % (n_done, n_samples))\n",
        "\n",
        "    return probs\n",
        "\n",
        "\n",
        "# optimizers\n",
        "# name(hyperp, tparams, grads, inputs (list), cost) = f_grad_shared, f_update\n",
        "def adadelta(lr, tparams, grads, inp, cost):\n",
        "    zipped_grads = [theano.shared(p.get_value() * numpy.float32(0.), name='%s_grad' % k) for k, p in tparams.items()]\n",
        "    running_up2 = [theano.shared(p.get_value() * numpy.float32(0.), name='%s_rup2' % k) for k, p in tparams.items()]\n",
        "    running_grads2 = [theano.shared(p.get_value() * numpy.float32(0.), name='%s_rgrad2' % k) for k, p in\n",
        "                      tparams.items()]\n",
        "\n",
        "    zgup = [(zg, g) for zg, g in zip(zipped_grads, grads)]\n",
        "    rg2up = [(rg2, 0.95 * rg2 + 0.05 * (g ** 2)) for rg2, g in zip(running_grads2, grads)]\n",
        "\n",
        "    f_grad_shared = theano.function(inp, cost, updates=zgup + rg2up)\n",
        "\n",
        "    updir = [-tensor.sqrt(ru2 + 1e-6) / tensor.sqrt(rg2 + 1e-6) * zg for zg, ru2, rg2 in\n",
        "             zip(zipped_grads, running_up2, running_grads2)]\n",
        "    ru2up = [(ru2, 0.95 * ru2 + 0.05 * (ud ** 2)) for ru2, ud in zip(running_up2, updir)]\n",
        "    param_up = [(p, p + ud) for p, ud in zip(itemlist(tparams), updir)]\n",
        "\n",
        "    f_update = theano.function([lr], [], updates=ru2up + param_up, on_unused_input='ignore')\n",
        "\n",
        "    return f_grad_shared, f_update\n",
        "\n",
        "\n",
        "def adam(lr, tparams, grads, inp, cost):\n",
        "    gshared = [theano.shared(p.get_value() * 0., name='%s_grad' % k) for k, p in tparams.items()]\n",
        "    gsup = [(gs, g) for gs, g in zip(gshared, grads)]\n",
        "\n",
        "    f_grad_shared = theano.function(inp, cost, updates=gsup)\n",
        "\n",
        "    lr0 = 0.0002\n",
        "    b1 = 0.1\n",
        "    b2 = 0.001\n",
        "    e = 1e-8\n",
        "\n",
        "    updates = []\n",
        "\n",
        "    i = theano.shared(numpy.float32(0.))\n",
        "    i_t = i + 1.\n",
        "    fix1 = 1. - b1 ** (i_t)\n",
        "    fix2 = 1. - b2 ** (i_t)\n",
        "    lr_t = lr0 * (tensor.sqrt(fix2) / fix1)\n",
        "\n",
        "    for p, g in zip(tparams.values(), gshared):\n",
        "        m = theano.shared(p.get_value() * 0.)\n",
        "        v = theano.shared(p.get_value() * 0.)\n",
        "        m_t = (b1 * g) + ((1. - b1) * m)\n",
        "        v_t = (b2 * tensor.sqr(g)) + ((1. - b2) * v)\n",
        "        g_t = m_t / (tensor.sqrt(v_t) + e)\n",
        "        p_t = p - (lr_t * g_t)\n",
        "        updates.append((m, m_t))\n",
        "        updates.append((v, v_t))\n",
        "        updates.append((p, p_t))\n",
        "    updates.append((i, i_t))\n",
        "\n",
        "    f_update = theano.function([lr], [], updates=updates, on_unused_input='ignore')\n",
        "\n",
        "    return f_grad_shared, f_update\n",
        "\n",
        "\n",
        "def rmsprop(lr, tparams, grads, inp, cost):\n",
        "    zipped_grads = [theano.shared(p.get_value() * numpy.float32(0.), name='%s_grad' % k) for k, p in tparams.items()]\n",
        "    running_grads = [theano.shared(p.get_value() * numpy.float32(0.), name='%s_rgrad' % k) for k, p in tparams.items()]\n",
        "    running_grads2 = [theano.shared(p.get_value() * numpy.float32(0.), name='%s_rgrad2' % k) for k, p in\n",
        "                      tparams.items()]\n",
        "\n",
        "    zgup = [(zg, g) for zg, g in zip(zipped_grads, grads)]\n",
        "    rgup = [(rg, 0.95 * rg + 0.05 * g) for rg, g in zip(running_grads, grads)]\n",
        "    rg2up = [(rg2, 0.95 * rg2 + 0.05 * (g ** 2)) for rg2, g in zip(running_grads2, grads)]\n",
        "\n",
        "    f_grad_shared = theano.function(inp, cost, updates=zgup + rgup + rg2up)\n",
        "\n",
        "    updir = [theano.shared(p.get_value() * numpy.float32(0.), name='%s_updir' % k) for k, p in tparams.items()]\n",
        "    updir_new = [(ud, 0.9 * ud - 1e-4 * zg / tensor.sqrt(rg2 - rg ** 2 + 1e-4)) for ud, zg, rg, rg2 in\n",
        "                 zip(updir, zipped_grads, running_grads, running_grads2)]\n",
        "    param_up = [(p, p + udn[1]) for p, udn in zip(itemlist(tparams), updir_new)]\n",
        "    f_update = theano.function([lr], [], updates=updir_new + param_up, on_unused_input='ignore')\n",
        "\n",
        "    return f_grad_shared, f_update\n",
        "\n",
        "\n",
        "def sgd(lr, tparams, grads, inp, cost):\n",
        "    gshared = [theano.shared(p.get_value() * 0., name='%s_grad' % k) for k, p in tparams.items()]\n",
        "    gsup = [(gs, g) for gs, g in zip(gshared, grads)]\n",
        "\n",
        "    f_grad_shared = theano.function(inp, cost, updates=gsup)\n",
        "\n",
        "    pup = [(p, p - lr * g) for p, g in zip(itemlist(tparams), gshared)]\n",
        "    f_update = theano.function([lr], [], updates=pup)\n",
        "\n",
        "    return f_grad_shared, f_update\n",
        "\n",
        "\n",
        "def perplexity(f_cost, lines, worddict, options, verbose=False, wv_embs=None):\n",
        "    n_lines = len(lines)\n",
        "    cost = 0.\n",
        "    n_words = 0.\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        # get array from line\n",
        "        wordin = wordpunct_tokenize(line.strip())\n",
        "        seq = [worddict[w] if w in worddict else 1 for w in wordin]\n",
        "        seq = [s if s < options['n_words'] else 1 for s in seq]\n",
        "        n_words += len(seq) + 1\n",
        "        x = numpy.array(seq + [0]).astype('int64').reshape([len(seq) + 1, 1])\n",
        "        x_mask = numpy.ones((len(seq) + 1, 1)).astype('float32')\n",
        "        if options['use_preemb']:\n",
        "            shp = x.shape\n",
        "            xi = wv_embs[x.flatten()].reshape([shp[0], shp[1], wv_embs.shape[1]])\n",
        "        else:\n",
        "            xi = x\n",
        "        cost_one = f_cost(x, x_mask, xi, x_mask) * (len(seq) + 1)\n",
        "        cost += cost_one\n",
        "\n",
        "        if verbose:\n",
        "            print('Sentence ', i, '/', n_lines, ' (', seq.mean(), '):', 2 ** (cost_one / len(seq) / numpy.log(2)), ', ',\n",
        "                  cost_one / len(seq))\n",
        "    cost = cost / n_words\n",
        "    return cost\n",
        "\n",
        "\n",
        "def padded(indices, maxlen):\n",
        "    if len(indices) > maxlen:\n",
        "        indices = indices[:maxlen]\n",
        "    elif len(indices) < maxlen:\n",
        "        indices = indices + [1] * (maxlen - len(indices))\n",
        "    return indices + [0]\n",
        "\n",
        "\n",
        "def get_embs(f_ctx, lines, worddict, options):\n",
        "    nw = options[\"n_words\"]\n",
        "    n_ex = len(lines)\n",
        "    batch_idx = range(int(n_ex / 1000))\n",
        "    remainder = (-(n_ex % 1000),n_ex)\n",
        "    indices = [(i*1000,(i+1)*1000) for i in batch_idx]\n",
        "    indices.append(remainder)\n",
        "    embs = []\n",
        "    for i in indices:\n",
        "        batch = lines[i[0]:i[1]]\n",
        "        seq = []\n",
        "        for i, line in enumerate(batch):\n",
        "            maxlen = options[\"maxlen\"]\n",
        "            # indices = [worddict[w.decode(\"utf-8\")] \\\n",
        "            #             if w.decode(\"utf-8\") in worddict \\\n",
        "            #             and worddict[w.decode(\"utf-8\")] < nw\\\n",
        "            #             else 1 for w in line]\n",
        "\n",
        "            indices = [worddict[w] \\\n",
        "                        if w in worddict \\\n",
        "                        and worddict[w] < nw\\\n",
        "                        and  w != \"#\"\\\n",
        "                        else 1 for w in line[7]]\n",
        "            # print(\"padded(indices, maxlen)\", padded(indices, maxlen))\n",
        "            seq.append(padded(indices, maxlen))\n",
        "        seq = numpy.array(seq).astype('int64')\n",
        "        x = numpy.swapaxes(seq,0,1)\n",
        "        x_mask = numpy.ones((seq.shape[1], seq.shape[0])).astype('float32')\n",
        "        # print(\"x_mask: \", x_mask)\n",
        "        emb = f_ctx(x, x_mask)\n",
        "        embs.extend(emb)\n",
        "    return embs\n",
        "\n",
        "\n",
        "def embedding(\n",
        "          model='model.npz',\n",
        "          save='embeddings.txt',\n",
        "          sentences='sentences.txt',\n",
        "          dictionary='sentences.txt.dict.pkl',\n",
        "):\n",
        "    \n",
        "    # load dictionary\n",
        "    with open(dictionary, 'rb') as f:\n",
        "        worddict = pkl.load(f)\n",
        "    # reload options\n",
        "    with open('%s.pkl'%model, 'rb') as f:\n",
        "        model_options = pkl.load(f)\n",
        "\n",
        "    print('Loading data')\n",
        "    examples = []\n",
        "    # classes = []\n",
        "    examples = pickle_load(sentences)\n",
        "    # with open(sentences, 'r') as f:\n",
        "        # for l in f:\n",
        "        #     # examples.append(l.split(\"\\t\")[0].lower().split())\n",
        "        #     examples.append(l.lower().split())\n",
        "        #     # classes.append(l.split(\"\\t\")[1].strip())\n",
        "\n",
        "    print('Building model')\n",
        "    params = init_params(model_options)\n",
        "    print(\"init_params: \", params.keys())\n",
        "\n",
        "    # reload parameters\n",
        "    params = load_params(model, params)\n",
        "    print(\"loaded params.\")\n",
        "\n",
        "    tparams = init_tparams(params)\n",
        "    trng, use_noise, \\\n",
        "          x, x_mask, x_noise, xn_mask, \\\n",
        "          ctx, \\\n",
        "          cost = \\\n",
        "          build_model(tparams, model_options)\n",
        "\n",
        "    # sentence representation\n",
        "    print('Building f_ctx...')\n",
        "    f_ctx = theano.function([x_noise, xn_mask], ctx)\n",
        "    \n",
        "    print('Getting embeddings...')\n",
        "    embs = get_embs(f_ctx, examples, worddict, model_options)\n",
        "    print('Saving...')\n",
        "    fout = open(save, \"w\")\n",
        "    # for e, c in zip(*(embs, classes)):\n",
        "    #     line = \" \".join([str(d) for d in e]) + \"\\t\" + c + \"\\n\"\n",
        "    #     fout.write(line)\n",
        "    for e in embs:\n",
        "        line = \" \".join([str(d) for d in e]) + \"\\n\"\n",
        "        fout.write(line)\n",
        "    fout.close()\n",
        "    print(\"Done.\")\n",
        "\n",
        "# main entrance\n",
        "if __name__ == '__main__':\n",
        "    embedding( model='model/marked_model_corrected_1.npz', \n",
        "            save='output_data/sdae_emb_corrected_1_train_tmp.txt',\n",
        "            sentences='output_data/training_masked_list.pkl',\n",
        "            dictionary='output_data/training_masked_list.pkl.dict.pkl'\n",
        "            )\n",
        "    \n",
        "    print_time(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data\n",
            "Building model\n",
            "init_params:  odict_keys(['Wemb', 'encoder_W', 'encoder_b', 'encoder_U', 'encoder_Wx', 'encoder_Ux', 'encoder_bx', 'ff_state_W', 'ff_state_b', 'decoder_W', 'decoder_b', 'decoder_U', 'decoder_Wx', 'decoder_Ux', 'decoder_bx', 'decoder_Wc', 'decoder_Wcx', 'ff_logit_W', 'ff_logit_b'])\n",
            "loaded params.\n",
            "Building f_ctx...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-152c3b217d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_data/sdae_emb_corrected_1_train_tmp.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_data/training_masked_list.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_data/training_masked_list.pkl.dict.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m             )\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-152c3b217d54>\u001b[0m in \u001b[0;36membedding\u001b[0;34m(model, save, sentences, dictionary)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;31m# sentence representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building f_ctx...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0mf_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxn_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting embeddings...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1839\u001b[0m                   name=name)\n\u001b[1;32m   1840\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_test_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[1;32m   1713\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[0;32m-> 1715\u001b[0;31m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[1;32m   1716\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m    697\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[1;32m    698\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/vm.py\u001b[0m in \u001b[0;36mmake_all\u001b[0;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m   1089\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m                                                  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m                                                  impl=impl))\n\u001b[0m\u001b[1;32m   1092\u001b[0m                 \u001b[0mlinker_make_thunk_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthunk_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lazy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 955\u001b[0;31m                                          no_recycling)\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 858\u001b[0;31m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1215\u001b[0m         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1216\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                                             \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                                             \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                                             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         return (thunk,\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[0;32m-> 1624\u001b[0;31m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mmodule_from_key\u001b[0;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m                 preargs=preargs)\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mcompile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m             \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_subprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2352\u001b[0m             \u001b[0mcompile_stderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/misc/windows.py\u001b[0m in \u001b[0;36moutput_subprocess_Popen\u001b[0;34m(command, **params)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# we need to use communicate to make sure we don't deadlock around\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# the stdout/stderr pipe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communication_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1532\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7XCsfx7WVC2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83707abc-1a5b-4efb-a31b-a12c35a214f9"
      },
      "source": [
        "# model = \"model/marked_model_corrected_1.npz\"\n",
        "# with open('%s.pkl'%model, 'rb') as f:\n",
        "#     model_options = pkl.load(f)\n",
        "# print(model_options)\n",
        "# pp = numpy.load(model)\n",
        "# for p in pp:\n",
        "#     print(p)\n",
        "\n",
        "\n",
        "# model = \"model/test_model_zg.npz\"\n",
        "# with open('%s.pkl'%model, 'rb') as f:\n",
        "#     model_options = pkl.load(f)\n",
        "# print(model_options)\n",
        "# pp = numpy.load(model)\n",
        "# for p in pp:\n",
        "#     print(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdwbhhqxcNye"
      },
      "source": [
        "# test logging\n",
        "# test 1, no print, \n",
        "# import logging\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
        "# logger = logging.getLogger()\n",
        "# logger.addHandler(logging.FileHandler('test_1_log_zg.log', 'a'))\n",
        "\n",
        "# print = logger.info\n",
        "\n",
        "# print(\"hello!\")\n",
        "\n",
        "# test 2, no print\n",
        "# log = open(\"test_2_log_zg.log\", \"a\")\n",
        "# sys.stdout = log\n",
        "# print(\"hello!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC91K14i0lXM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8d5fd925-70e1-466a-c5c7-64f3118e79e6"
      },
      "source": [
        "# build dictionary from token lists\n",
        "'''\n",
        "def build_dictionary(filename):\n",
        "    rows = pickle_load(filename)\n",
        "    s = set(\".\")\n",
        "    d = {}\n",
        "    for row in rows:\n",
        "        token_list = row[6]\n",
        "        s.update(token_list)\n",
        "\n",
        "    for i, ss in enumerate(s):\n",
        "        d[ss] = i\n",
        "\n",
        "    return d\n",
        "\n",
        "D = build_dictionary(\"output_data/testing_masked_list.pkl\")\n",
        "# training: 13580; testing: 3946\n",
        "print(len(D))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef build_dictionary(filename):\\n    rows = pickle_load(filename)\\n    s = set(\".\")\\n    d = {}\\n    for row in rows:\\n        token_list = row[6]\\n        s.update(token_list)\\n\\n    for i, ss in enumerate(s):\\n        d[ss] = i\\n\\n    return d\\n\\nD = build_dictionary(\"output_data/testing_masked_list.pkl\")\\n# training: 13580; testing: 3946\\nprint(len(D))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mta8noPlbcqb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f0909f3-6c95-4b1d-e5c9-666ec7f17794"
      },
      "source": [
        "# ========================================\n",
        "# compare with BOW n-gram\n",
        "# get labels from original data\n",
        "# ========================================\n",
        "\n",
        "# sample_size = 1400\n",
        "\n",
        "def return_labels(filename):\n",
        "    reader = csv.reader(open(filename, newline='', encoding='utf-8'), delimiter=',',\n",
        "                        quotechar='\"')\n",
        "    row_cnt = 0\n",
        "    labels = []\n",
        "\n",
        "    try:\n",
        "        for row in reader:\n",
        "            row_cnt += 1\n",
        "            if row_cnt == 1:\n",
        "                continue\n",
        "\n",
        "            # if row_cnt > sample_size:\n",
        "            #     break\n",
        "            labels.append(int(row[5]))\n",
        "\n",
        "    except Exception as ex:\n",
        "        sys.stderr.write('Exception\\n')\n",
        "        extype, exvalue, extrace = sys.exc_info()\n",
        "        traceback.print_exception(extype, exvalue, extrace)\n",
        "\n",
        "    return labels\n",
        "\n",
        "def return_embs(filename):\n",
        "    reader = csv.reader(open(filename, newline='', encoding='utf-8'), delimiter=',',\n",
        "                        quotechar='\"')\n",
        "    row_cnt = 0\n",
        "    embs = []\n",
        "\n",
        "    try:\n",
        "        for row in reader:\n",
        "            row_cnt += 1\n",
        "            emb_str = str(row[0])\n",
        "            emb = np.fromstring(emb_str, sep = \" \")\n",
        "            embs.append(emb)\n",
        "\n",
        "    except Exception as ex:\n",
        "        sys.stderr.write('Exception\\n')\n",
        "        extype, exvalue, extrace = sys.exc_info()\n",
        "        traceback.print_exception(extype, exvalue, extrace)\n",
        "\n",
        "    return embs\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "def my_tokenizer(s):\n",
        "    return s.split()\n",
        "\n",
        "\n",
        "def return_corpus(filename, variant):\n",
        "    row_cnt = 0\n",
        "    corpus_proc = []\n",
        "\n",
        "    rows = pickle_load(filename)\n",
        "\n",
        "    for row in rows:\n",
        "        row_cnt += 1\n",
        "\n",
        "        # if row_cnt > 1399:\n",
        "        #     break\n",
        "\n",
        "        text = row[1]\n",
        "        if variant == \"raw\":\n",
        "            text = \" \".join(row[6])\n",
        "        elif variant == \"mask\":\n",
        "            text = \" \".join(row[7])\n",
        "        elif variant ==  \"remove\":\n",
        "            text = \" \".join([x for x in row[7] if x != \"#\"])\n",
        "            \n",
        "        corpus_proc.append(text)\n",
        "\n",
        "    return corpus_proc\n",
        "\n",
        "\n",
        "def return_bow(corpus_proc):\n",
        "    bow = []\n",
        "    vectorizer = CountVectorizer(tokenizer=my_tokenizer,ngram_range=(1,1),max_features=30000)\n",
        "    X = vectorizer.fit_transform(corpus_proc)\n",
        "    # print(vectorizer.get_feature_names())\n",
        "    X_list = list(X.toarray()) # 2d numpy array\n",
        "    \n",
        "    for x in X_list:\n",
        "        bow.append(np.array(x))\n",
        "\n",
        "    return bow\n",
        "\n",
        "# labels = return_labels(\"output_data/training_marked.csv\")\n",
        "# embs = return_embs(\"output_data/sdae_emb_corrected_1.txt\")\n",
        "sdae_test_labels = return_labels(\"output_data/testing_marked.csv\")\n",
        "sdae_test_embs = return_embs(\"output_data/sdae_emb_corrected_1_tmp.txt\") #  sdae_emb_corrected_1_testset\n",
        "\n",
        "sdae_train_labels = return_labels(\"output_data/training_marked.csv\")\n",
        "sdae_train_embs = return_embs(\"output_data/sdae_emb_corrected_1_train_tmp.txt\")\n",
        "\n",
        "# corpus_proc = return_corpus(\"output_data/training_masked_list.pkl\", \"mask\")\n",
        "# bow_emb = return_bow(corpus_proc)\n",
        "# print(len(corpus_proc), len(bow_emb))\n",
        "# print(len(labels), len(bow_emb))\n",
        "# print(len(bow_emb[0]))\n",
        "\n",
        "print_time(\"test: \", str(len(sdae_test_embs)), \", train: \", str(len(sdae_train_embs)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2019-12-09 22:43:11.103056 ] test: 704, train: 6328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw7lkA-ZOqU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "90e04340-3c12-435e-954a-89ebd064d6f2"
      },
      "source": [
        "# validate embeddings\n",
        "# input_list = pickle_load(\"output_data/testing_masked_list.pkl\")\n",
        "# print(len(input_list))\n",
        "\n",
        "# print(len(sdae_test_embs))\n",
        "\n",
        "# with open(\"output_data/testing_corpus.txt\", 'r') as txtfile:\n",
        "#     row_cnt = 0\n",
        "#     for row in txtfile.readlines():\n",
        "#         row_cnt+=1\n",
        "#     print(row_cnt)\n",
        "\n",
        "print(sdae_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNaI2QygLhJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a072b4be-5f24-417b-fc60-18639acde7a3"
      },
      "source": [
        "# ========================================\n",
        "# compare pretrained embeddings and SDAE performance\n",
        "# ========================================\n",
        "\n",
        "# ------- ELMo --------\n",
        "# elmo_train_pkl = pickle_load(\"output_data/Elmo_training_marked_vecs.txt.dict.pkl\")\n",
        "# elmo_train_pkl = pickle_load(\"output_data/Elmo_training_marked1_vecs.txt.dict.pkl\")\n",
        "elmo_train_pkl = pickle_load(\"output_data/Elmo_training_tokens1_vecs.txt.dict.pkl\")\n",
        "elmo_train_embs = [row[2] for row in elmo_train_pkl]\n",
        "elmo_train_labels = [int(row[1]) for row in elmo_train_pkl]\n",
        "\n",
        "# elmo_test_pkl = pickle_load(\"output_data/Elmo_testing_marked_vecs.txt.dict.pkl\")\n",
        "# elmo_test_pkl = pickle_load(\"output_data/Elmo_testing_marked1_vecs.txt.dict.pkl\")\n",
        "elmo_test_pkl = pickle_load(\"output_data/Elmo_testing_tokens1_vecs.txt.dict.pkl\")\n",
        "elmo_test_embs = [row[2] for row in elmo_test_pkl]\n",
        "elmo_test_labels = [int(row[1]) for row in elmo_test_pkl]\n",
        "\n",
        "elmo_clf = LogisticRegression(random_state=0, solver='liblinear').fit(elmo_train_embs, elmo_train_labels)\n",
        "elmo_predict_labels = elmo_clf.predict(elmo_test_embs)\n",
        "\n",
        "print(elmo_clf.score(elmo_test_embs, elmo_test_labels))\n",
        "# print(\"elmo: \", elmo_predict_labels)\n",
        "# marked: 0.796875; unmarked: 0.81\n",
        "\n",
        "\n",
        "# ------- SDAE   --------\n",
        "sdae_train_embs = return_embs(\"output_data/sdae_emb_corrected_1.txt\") # sdae_emb_corrected_1 vs. sdae_emb_corrected_1_train_tmp \n",
        "sdae_test_embs = return_embs(\"output_data/sdae_emb_corrected_1_testset.txt\") # sdae_emb_corrected_1_testset vs. sdae_emb_corrected_1_tmp\n",
        "\n",
        "sdae_clf = LogisticRegression(random_state=0, solver='liblinear').fit(sdae_train_embs, elmo_train_labels)\n",
        "sdae_predict_labels = sdae_clf.predict(sdae_test_embs)\n",
        "# print(\"sdae: \", sdae_predict_labels)\n",
        "print(sdae_clf.score(sdae_test_embs, sdae_test_labels))\n",
        "# 0.609375\n",
        "print(sdae_test_labels)\n",
        "\n",
        "# ------- USE   --------\n",
        "use_train_pkl = pickle_load(\"output_data/training_USE_tokens_vecs.txt.dict.pkl\")\n",
        "use_train_embs = [row[2][0] for row in use_train_pkl]\n",
        "use_train_labels = [int(row[1]) for row in use_train_pkl]\n",
        "\n",
        "use_test_pkl = pickle_load(\"output_data/testing_USE_tokens_vecs.txt.dict.pkl\")\n",
        "use_test_embs = [row[2][0] for row in use_test_pkl]\n",
        "use_test_labels = [int(row[1]) for row in use_test_pkl]\n",
        "\n",
        "use_clf = LogisticRegression(random_state=0, solver='liblinear').fit(use_train_embs, use_train_labels)\n",
        "use_predict_labels = use_clf.predict(use_test_embs)\n",
        "\n",
        "print(use_clf.score(use_test_embs, use_test_labels))\n",
        "\n",
        "\n",
        "# ------- USE   --------\n",
        "\n",
        "w2v_train_pkl = pickle_load(\"output_data/training_word_vec_tokens_vecs.txt.dict.pkl\")\n",
        "w2v_train_embs = [row[2] for row in w2v_train_pkl]\n",
        "w2v_train_labels = [int(row[1]) for row in w2v_train_pkl]\n",
        "\n",
        "w2v_test_pkl = pickle_load(\"output_data/testing_word_vec_tokens_vecs.txt.dict.pkl\")\n",
        "w2v_test_embs = [row[2] for row in w2v_test_pkl]\n",
        "w2v_test_labels = [int(row[1]) for row in w2v_test_pkl]\n",
        "\n",
        "w2v_clf = LogisticRegression(random_state=0, solver='liblinear').fit(w2v_train_embs, w2v_train_labels)\n",
        "w2v_predict_labels = w2v_clf.predict(w2v_test_embs)\n",
        "\n",
        "print(w2v_clf.score(w2v_test_embs, w2v_test_labels))\n",
        "print_time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8167613636363636\n",
            "0.609375\n",
            "[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0]\n",
            "0.8096590909090909\n",
            "0.7951635846372689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM4FMOGRbn0O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e64fc28-2bd1-4eb4-c720-3439d7328651"
      },
      "source": [
        "# ========================================\n",
        "# compare classifier performance\n",
        "# ========================================\n",
        "\n",
        "def get_binary_labels(orig_labels):\n",
        "    threshold = 0.7\n",
        "    bi_labels = [1 if x>threshold else 0 for x in orig_labels]\n",
        "    return bi_labels\n",
        "\n",
        "\n",
        "def calculate_auc_roc(test_label_trans, predict_label_trans):\n",
        "    \n",
        "    print('ROC-AUC: ', roc_auc_score(test_label_trans, predict_label_trans))\n",
        "    fpr, tpr, thresholds = roc_curve(test_label_trans, predict_label_trans, pos_label=1)\n",
        "\n",
        "    print(classification_report(test_label_trans, get_binary_labels(predict_label_trans)))\n",
        "\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    import matplotlib\n",
        "    # matplotlib.use(\"TkAgg\")\n",
        "    matplotlib.rcParams.update({'font.size': 20})\n",
        "    f=plt.figure()\n",
        "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.plot([0, 1], [0, 1], 'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def calculate_ap(test_label_trans, predict_label_trans):\n",
        "    average_precision = average_precision_score(test_label_trans, predict_label_trans)\n",
        "\n",
        "    print('PRC for skip-chain CRF with sub-sequences \\n {0:0.2f}'.format(\n",
        "          average_precision))\n",
        "\n",
        "    # plot PRC\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(test_label_trans, predict_label_trans)\n",
        "\n",
        "    pos_rate = sum(test_label_trans)/len(predict_label_trans)\n",
        "#     import matplotlib\n",
        "    f=plt.figure()\n",
        "    matplotlib.rcParams.update({'font.size': 20})\n",
        "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
        "    step_kwargs = ({'step': 'post'}\n",
        "                   if 'step' in signature(plt.fill_between).parameters\n",
        "                   else {})\n",
        "    plt.step(recall, precision, color='b', alpha=0.2,\n",
        "             where='post', label='AP = %0.2f' % average_precision)\n",
        "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "    plt.plot([0, 1], [pos_rate, pos_rate], 'r--')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    \n",
        "    \n",
        "def calculate_mrr(test_label, predict_result):\n",
        "    ranked_results = []\n",
        "\n",
        "    for i in range(len(predict_result)):\n",
        "        list1 = test_label[i]\n",
        "        list2 = predict_result[i]\n",
        "\n",
        "        list2_ranked, list1_ranked = zip(*sorted(zip(list2,list1), reverse=True))\n",
        "#         list1_ranked_int = list(map(int, list1_ranked))\n",
        "        list1_ranked_int = list1_ranked\n",
        "#         list1_ranked_int = get_binary_labels(list1_ranked)\n",
        "        ranked_results.append(list1_ranked_int)\n",
        "        if i<3:\n",
        "            print(ranked_results)\n",
        "\n",
        "\n",
        "    rs = (np.asarray(r).nonzero()[0] for r in ranked_results)\n",
        "\n",
        "    mrr = np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
        "\n",
        "    print(\"mrr: \", mrr)\n",
        "\n",
        "\n",
        "def run_lr(data_set, data_label, metrics):\n",
        "    # print(\"----- LR -----\")\n",
        "\n",
        "    predicted = cross_validate(LogisticRegression(solver='liblinear'), data_set, data_label, cv=3, scoring=(metrics), return_train_score=True) #, class_weight='balanced'\n",
        "\n",
        "    return predicted\n",
        "\n",
        "# run_lr(embs, labels)\n",
        "# predicted = run_lr(use_train_embs, train_labels, 'f1')\n",
        "# run_lr(bow_emb,labels)\n",
        "print_time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2019-12-09 03:36:47.023248 ] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKf4jHIevhAq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9YZWDSxG8fZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87211170-a75a-476a-ba6a-b5d09713b6d6"
      },
      "source": [
        "# ========================================\n",
        "# cross-validation results (a sense of overfitting)\n",
        "# ========================================\n",
        "# ELMo\n",
        "elmo_train_pkl = pickle_load(\"output_data/Elmo_training_tokens1_vecs.txt.dict.pkl\")\n",
        "elmo_train_embs = [row[2] for row in elmo_train_pkl]\n",
        "elmo_train_labels = [int(row[1]) for row in elmo_train_pkl]\n",
        "\n",
        "# ELMo masked\n",
        "elmo_mask_train_pkl = pickle_load(\"output_data/Elmo_training_marked1_vecs.txt.dict.pkl\")\n",
        "elmo_mask_train_embs = [row[2] for row in elmo_mask_train_pkl]\n",
        "elmo_mask_train_labels = [int(row[1]) for row in elmo_mask_train_pkl]\n",
        "\n",
        "# word2vec\n",
        "w2v_train_pkl = pickle_load(\"output_data/training_word_vec_tokens_vecs.txt.dict.pkl\")\n",
        "w2v_train_embs = [row[2] for row in w2v_train_pkl]\n",
        "w2v_train_labels = [int(row[1]) for row in w2v_train_pkl]\n",
        "\n",
        "# word2vec masked\n",
        "w2v_mask_train_pkl = pickle_load(\"output_data/training_word_vec_marked_vecs.txt.dict.pkl\")\n",
        "w2v_mask_train_embs = [row[2] for row in w2v_mask_train_pkl]\n",
        "w2v_mask_train_labels = [int(row[1]) for row in w2v_mask_train_pkl]\n",
        "\n",
        "# USE sentence encoding\n",
        "use_train_pkl = pickle_load(\"output_data/training_USE_tokens_vecs.txt.dict.pkl\")\n",
        "use_train_embs = [row[2][0] for row in use_train_pkl]\n",
        "use_train_labels = [int(row[1]) for row in use_train_pkl]\n",
        "\n",
        "# USE masked\n",
        "use_mask_train_pkl = pickle_load(\"output_data/training_USE_marked_vecs.txt.dict.pkl\")\n",
        "use_mask_train_embs = [row[2][0] for row in use_mask_train_pkl]\n",
        "use_mask_train_labels = [int(row[1]) for row in use_mask_train_pkl]\n",
        "\n",
        "\n",
        "examine_data = {\n",
        "    \"elmo\": (elmo_train_embs, elmo_train_labels),\n",
        "    \"elmo_mask\": (elmo_mask_train_embs, elmo_mask_train_labels),\n",
        "    \"use\": (use_train_embs, use_train_labels),\n",
        "    \"use_mask\": (use_mask_train_embs, use_mask_train_labels),\n",
        "    \"w2v\": (w2v_train_embs, w2v_train_labels),\n",
        "    \"w2v_mask\": (w2v_mask_train_embs, w2v_mask_train_labels),\n",
        "    \"sdae\": (sdae_train_embs, sdae_train_labels)\n",
        "}\n",
        "\n",
        "# for key in examine_data.keys():\n",
        "#     embs = examine_data.get(key)[0]\n",
        "#     labels = examine_data.get(key)[1]\n",
        "#     print(\"----- \", key) \n",
        "#     for m in ('f1', 'accuracy', 'precision', 'roc_auc'):\n",
        "#         predicted = run_lr(embs, labels, m)\n",
        "#         # predicted = run_lr(sdae_train_embs, sdae_train_labels, m)\n",
        "#         mean_score = np.mean(predicted.get(\"test_score\"))\n",
        "#         mean_score_training = np.mean(predicted.get(\"train_score\"))\n",
        "#         print(mean_score, mean_score_training)\n",
        "\n",
        "print_time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2019-12-09 03:36:55.977632 ] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0hYE7UkYJZq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "023f5ded-129b-49a7-8e49-c2f48ba00b8c"
      },
      "source": [
        "# test\n",
        "\n",
        "for key in [\"w2v\", \"use\", \"elmo\", \"sdae\"]:\n",
        "    print(\"----- \", key)\n",
        "    embs = examine_data.get(key)[0]\n",
        "    labels = examine_data.get(key)[1]\n",
        "    for m in ('f1', 'accuracy', 'precision', 'roc_auc'):\n",
        "        predicted = run_lr(embs, labels, m)\n",
        "        # predicted = run_lr(sdae_train_embs, sdae_train_labels, m)\n",
        "        mean_score = np.mean(predicted.get(\"test_score\"))\n",
        "        mean_score_training = np.mean(predicted.get(\"train_score\"))\n",
        "        drop = mean_score_training - mean_score\n",
        "        print(m, mean_score, mean_score_training, drop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----  w2v\n",
            "f1 0.7504103950856919 0.7647922439137401 0.014381848828048271\n",
            "accuracy 0.7731238429081233 0.7864823295126184 0.013358486604495123\n",
            "precision 0.7518717803990639 0.7674302564928247 0.01555847609376082\n",
            "roc_auc 0.8355330862339626 0.8590766958943806 0.02354360966041802\n",
            "-----  use\n",
            "f1 0.7776290057183534 0.7918041865177141 0.014175180799360754\n",
            "accuracy 0.7948806626531745 0.8081544075730775 0.013273744919903074\n",
            "precision 0.767658137010642 0.7825464367533507 0.014888299742708666\n",
            "roc_auc 0.865522917630798 0.8827731702889371 0.017250252658139065\n",
            "-----  elmo\n",
            "f1 0.7380900514074801 0.798253806078156 0.06016375467067592\n",
            "accuracy 0.7779731340220241 0.8269600484580337 0.048986914436009665\n",
            "precision 0.7957626266000482 0.8505953511904445 0.05483272459039634\n",
            "roc_auc 0.8493229493861306 0.9093459053994032 0.060022956013272566\n",
            "-----  sdae\n",
            "f1 0.7290319866532248 0.7313504919585566 0.0023185053053318416\n",
            "accuracy 0.754424616684532 0.7560840115573714 0.0016593948728393926\n",
            "precision 0.7325594909678621 0.7334710726616916 0.000911581693829544\n",
            "roc_auc 0.826834204095595 0.8326613137036176 0.005827109608022574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_WoKFMbXKA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "e025120d-6b01-4223-fad6-773cd59bb1f0"
      },
      "source": [
        "# ========================================\n",
        "# get top n similiar sentences:\n",
        "# ========================================\n",
        "import heapq \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import scipy\n",
        "\n",
        "# def get_idx_sentence_mapping(idx)\n",
        "idx_sent_map = {}\n",
        "idx_entry_map = {}\n",
        "raw_list = pickle_load(\"output_data/training_masked_list.pkl\")\n",
        "\n",
        "SENTENCE_ID_COL = 0\n",
        "SENTENCE_COL = 1\n",
        "RAW_SPLIT_COL = 6\n",
        "MASK_SPLIT_COL = 7\n",
        "\n",
        "num_top = 3\n",
        "\n",
        "for idx,r in enumerate(raw_list):\n",
        "    idx_sent_map[idx] = (r[0],r[1])\n",
        "    idx_entry_map[idx] = r\n",
        "\n",
        "\n",
        "def get_n_similar(embs, input_idx, n):\n",
        "    dist_list = []\n",
        "    # heapq.heapify(simi_heapq)\n",
        "    input_emb = embs[input_idx]\n",
        "\n",
        "    for idx, vec in enumerate(embs):\n",
        "        if idx == input_idx:\n",
        "            continue\n",
        "        \n",
        "        dist = scipy.spatial.distance.cosine(input_emb, vec)        \n",
        "        dist_list.append((dist,idx))\n",
        "\n",
        "    # print(\"input: \", input_idx, idx_sent_map.get(input_idx))\n",
        "    top_simi = []\n",
        "    for i in heapq.nsmallest(n,dist_list):\n",
        "        dist = i[0]\n",
        "        idx = i[1]\n",
        "        sent_id = idx_entry_map.get(idx)[SENTENCE_ID_COL]\n",
        "        sent = idx_entry_map.get(idx)[SENTENCE_COL]\n",
        "        entry = (idx, sent_id, sent, dist)\n",
        "        top_simi.append(entry)\n",
        "        # print(\"list idx\", i[1], \"| (id, sentence):\", idx_sent_map.get(i[1]))\n",
        "    return top_simi # heapq.nsmallest(n,dist_list)\n",
        "\n",
        "sample_idx = 737\n",
        "\n",
        "# sample training idx 737, id 3833, \"My village Town Hall built with a huge sum of money has been swallowed,\" he said.\n",
        "# sample training idx 0, id 2864, In the last four years, the Maoists have killed more than 900 Indian security officers, a figure almost as high as the more than 1,100 members of the coalition forces killed in Afghanistan during the same period.\n",
        "\n",
        "print(\"input: \", idx_entry_map.get(sample_idx)[SENTENCE_COL])\n",
        "\n",
        "for key in [\"elmo\", \"elmo_mask\", \"w2v\", \"w2v_mask\", \"use\", \"use_mask\", \"sdae\"]:    #[\"elmo\", \"elmo_mask\", \"w2v\", \"w2v_mask\", \"use\", \"use_mask\", \"sdae\"]:\n",
        "    print(\"------------ \", key)\n",
        "    embs = examine_data.get(key)[0]\n",
        "    top_simi = get_n_similar(embs,sample_idx,num_top)\n",
        "    print(\"top_simi: \", top_simi)\n",
        "\n",
        "print_time()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input:  \"My village Town Hall built with a huge sum of money has been swallowed,\" he said.\n",
            "------------  elmo\n",
            "top_simi:  [(667, '6544', '\"We have a shortage of resources,\" he said.', 0.17784839868545532), (1039, '6565', '\"We just heard this real roar, I thought we were about to lose half our roof,\" she said.', 0.18492305278778076), (3600, '5176', '\"The arrival of Mr. Shannon was key,\" he said.', 0.18993449211120605)]\n",
            "------------  elmo_mask\n",
            "top_simi:  [(2881, '1485', 'Eschol Amelia \"Amy\" Studnitz had been working for Corporate Mailing Services since August 2008 as a senior accountant.', 0.05905866622924805), (4926, '6328', \"Treece said O'Quinn's personal property has been left to the foundation that served his charitable giving.\", 0.060838162899017334), (6030, '225', 'A large debris field has been located, and debris has been collected, he said.', 0.061478376388549805)]\n",
            "------------  w2v\n",
            "top_simi:  [(3448, '491', 'Another man arrived on a motorcycle from a more distant village.', 0.10370123386383057), (2698, '2073', 'His line for the night was 22 points, 8 rebounds, 4 assists, and 3 steals.', 0.1248025894165039), (5432, '4472', 'Repeat.', 0.12674486637115479)]\n",
            "------------  w2v_mask\n",
            "top_simi:  [(3538, '2045', \"Hi, I am new to Ubuntu, I honestly love it, I looking forward for the switch to Linux, my only issue so far is with my Thinkpad t40 2373 - 237375U with the wireless driver, it doesn't recognize my wireless, if some one could tell me where can I find a driver for it, or work a way around.\", 0.044134438037872314), (3703, '3398', 'I will use this for sure, but I also wonder if there is any way to map the eject -t command to the keyboard or make an Applet or something?', 0.06013011932373047), (4799, '5075', 'That kind of cutting-edge idea seems like it would be exactly what Michael Jackson would embrace.', 0.08043462038040161)]\n",
            "------------  use\n",
            "top_simi:  [(5090, '3769', \"Mr. Ramesh said 70 percent of India's iron ore lay in states infiltrated by Maoists; production in this area is stalled at 16 million tons a year even though the area has the potential to produce 100 million tons.\", 0.31543511152267456), (794, '3631', \"Maoists sabotaged Essar's 166-mile underground pipeline, which transfers slurry from one of India's most coveted iron ore deposits to the Bay of Bengal.\", 0.3998812437057495), (3008, '680', 'Asked about the damning report of the Tiruvallur collector\\'s report about alleged encroachment of 197 acres of land by him in Kaverirajapuran village, Justice Dinakaran had said that \"the collector has got his facts wrong\".', 0.4058980345726013)]\n",
            "------------  use_mask\n",
            "top_simi:  [(5569, '5071', '\"That is my flag,\" he says.', 0.19382846355438232), (5488, '1976', 'He \"seems to have support across a number of constituencies. And I like his views on city planning,\" Yeoman said.', 0.20596539974212646), (4992, '5856', 'The river is what he knows.', 0.23798000812530518)]\n",
            "------------  sdae\n",
            "top_simi:  [(1722, '4229', '\"People must remember most balconies are designed in reality for a family group,\" Insp Davies said.', 0.001856437646207576), (4637, '3903', '\"No modern state can accept attacks on state institutions, even when the state is wrong.\"', 0.0019840372666376505), (1630, '5982', '\"The Tories making cuts now and cuts next year are putting the recovery at risk.\"', 0.0025802172552233937)]\n",
            "[ 2019-12-09 03:37:05.455376 ] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcZ0Y9Y4JwCG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d9d60d38-5c05-4a6a-9153-d0ff04188e88"
      },
      "source": [
        "# test\n",
        "sample_idx = 737\n",
        "num_top = 3\n",
        "tmp_embs = examine_data.get(\"elmo\")[0]\n",
        "top_simi = get_n_similar(tmp_embs,sample_idx,num_top)\n",
        "print(\"top_simi: \", top_simi)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top_simi:  [(667, '6544', '\"We have a shortage of resources,\" he said.', 0.17784839868545532), (1039, '6565', '\"We just heard this real roar, I thought we were about to lose half our roof,\" she said.', 0.18492305278778076), (3600, '5176', '\"The arrival of Mr. Shannon was key,\" he said.', 0.18993449211120605)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmcBp4rjrGMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7cfce30a-d35c-496b-dc39-a8010c4dd8e8"
      },
      "source": [
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     import doctest\n",
        "#     doctest.testmod()\n",
        "\n",
        "# sample_idx = 737\n",
        "\n",
        "raw_masked_split = idx_entry_map.get(sample_idx)[MASK_SPLIT_COL]\n",
        "\n",
        "# save to pickle wer_result_dict = {\"elmo\": [{\"input\": (idx, id, sentence), \"selected_1\": (idx,id,sentence,dist,wer), \"selected_2\": , \"selected_3\": , \"avg_wer\": top3_avg_wer_rate)}],\n",
        "            # \"use\":  [{\"input\": (idx, id, sentence), \"selected_1\": , \"selected_2\": , \"selected_3\": , \"avg_wer\": top3_avg_wer_rate)},{...}, ...] ...\n",
        "\n",
        "print_time(\"calculating wer...\")\n",
        "wer_result_dict = {}\n",
        "for key in [\"use\"]:     # [\"elmo\", \"elmo_mask\", \"w2v\", \"w2v_mask\", \"use\", \"use_mask\", \"sdae\"]\n",
        "    sum_wer_by_key = 0\n",
        "    wer_result_dict[key] = []\n",
        "    for sample_idx in range(0,len(idx_entry_map)):\n",
        "        if sample_idx % 2000 == 0:\n",
        "            print_time(key, \", \", str(sample_idx))\n",
        "        embs = examine_data.get(key)[0]\n",
        "        input_id = idx_entry_map.get(sample_idx)[SENTENCE_ID_COL]\n",
        "        input_sent = idx_entry_map.get(sample_idx)[SENTENCE_COL]\n",
        "        sample_input = (sample_idx, input_id, input_sent)\n",
        "\n",
        "        top_simi = get_n_similar(embs,sample_idx,num_top)\n",
        "        top3_sum_wer_rate = 0.0\n",
        "        # print(\"------ \", key)\n",
        "        selected_entry = []\n",
        "        for i, (idx, sent_id, sent, dist) in enumerate(top_simi):\n",
        "            selected_masked_split = idx_entry_map.get(idx)[MASK_SPLIT_COL]\n",
        "            wer_dist = adapted_wer(raw_masked_split, selected_masked_split)\n",
        "            # print(raw_masked_split)\n",
        "            # print(selected_masked_split)\n",
        "            # print(wer_dist)\n",
        "            wer_rate = wer_dist / len(raw_masked_split)\n",
        "            selected_entry.append((idx, sent_id, sent, dist, wer_rate))\n",
        "            top3_sum_wer_rate += wer_rate\n",
        "\n",
        "        top3_avg_wer_rate = top3_sum_wer_rate / 3.0\n",
        "        this_sample = {\"input\": sample_input,\n",
        "                       \"selected_1\": selected_entry[0],\n",
        "                       \"selected_2\": selected_entry[1],\n",
        "                       \"selected_3\": selected_entry[2],\n",
        "                       \"avg_wer\": top3_avg_wer_rate\n",
        "        }\n",
        "        wer_result_dict.get(key).append(this_sample)\n",
        "        # print(key, \": \", top3_avg_wer_rate)\n",
        "        sum_wer_by_key += top3_avg_wer_rate\n",
        "    avg_wer_by_key = sum_wer_by_key / len(idx_entry_map)    \n",
        "    print(key,  avg_wer_by_key)    \n",
        "\n",
        "print_time(\"done\")\n",
        "\n",
        "# [ 2019-12-06 21:21:07.547086 ] calculating wer...\n",
        "# [ 2019-12-06 21:21:07.558269 ] use, 0\n",
        "# [ 2019-12-06 21:34:30.121963 ] use, 2000\n",
        "# [ 2019-12-06 21:47:58.976531 ] use, 4000\n",
        "# [ 2019-12-06 22:01:20.676744 ] use, 6000\n",
        "# use 0.46128061628279626\n",
        "# [ 2019-12-06 16:52:20.933022 ] calculating wer...\n",
        "# [ 2019-12-06 16:52:20.934027 ] use_mask, 0\n",
        "# [ 2019-12-06 17:05:45.124735 ] use_mask, 2000\n",
        "# [ 2019-12-06 17:19:10.318847 ] use_mask, 4000\n",
        "# [ 2019-12-06 17:32:31.875477 ] use_mask, 6000\n",
        "# use_mask 0.6143357564264627\n",
        "# [ 2019-12-06 17:34:42.980073 ] sdae, 0\n",
        "# [ 2019-12-06 17:43:21.121699 ] sdae, 2000\n",
        "# [ 2019-12-06 17:52:00.575388 ] sdae, 4000\n",
        "# [ 2019-12-06 18:00:39.874949 ] sdae, 6000\n",
        "# sdae 0.6306218394437425\n",
        "# [ 2019-12-06 18:02:04.642694 ] done"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2019-12-06 21:21:07.547086 ] calculating wer...\n",
            "[ 2019-12-06 21:21:07.558269 ] use, 0\n",
            "[ 2019-12-06 21:34:30.121963 ] use, 2000\n",
            "[ 2019-12-06 21:47:58.976531 ] use, 4000\n",
            "[ 2019-12-06 22:01:20.676744 ] use, 6000\n",
            "use 0.46128061628279626\n",
            "[ 2019-12-06 22:03:31.509665 ] done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8NYm2ur6hB0"
      },
      "source": [
        "# merge single files to wer_result_dict\n",
        "\n",
        "# wer_result_dict = {}\n",
        "\n",
        "# elmo_selects = pickle_load(\"selected_elmo.pkl\")\n",
        "# wer_result_dict[\"elmo\"] = elmo_selects\n",
        "\n",
        "# dict_reload = pickle_load(\"selected_use.pkl\")\n",
        "# wer_result_dict[\"use\"] = dict_reload.get(\"use\")\n",
        "\n",
        "# dict_reload = pickle_load(\"selected_use_mask_sdae.pkl\")\n",
        "# wer_result_dict[\"use_mask\"] = dict_reload.get(\"use_mask\")\n",
        "# wer_result_dict[\"sdae\"] = dict_reload.get(\"sdae\")\n",
        "\n",
        "# dict_reload = pickle_load(\"selected_elmo_mask_w2v.pkl\")\n",
        "# wer_result_dict[\"elmo_mask\"] = dict_reload.get(\"elmo_mask\")\n",
        "# wer_result_dict[\"w2v\"] = dict_reload.get(\"w2v\")\n",
        "\n",
        "# dict_reload = pickle_load(\"selected_w2v_mask.pkl\")\n",
        "# wer_result_dict[\"w2v_mask\"] = dict_reload.get(\"w2v_mask\")\n",
        "\n",
        "# pickle_save(\"analysis/all_selected_wer.pkl\", wer_result_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIlC88xHDeYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20590344-d6c6-4740-ff06-0ca3d3dbffff"
      },
      "source": [
        "# ========================================\n",
        "# reload wer_result_dict\n",
        "# ========================================\n",
        "\n",
        "wer_result_dict =  pickle_load(\"analysis/all_selected_wer.pkl\")\n",
        "print(wer_result_dict.keys())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['elmo', 'use', 'use_mask', 'sdae', 'elmo_mask', 'w2v', 'w2v_mask'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVobvMeyDEyU"
      },
      "source": [
        "# measure with WER(word error rate) for structual similarity\n",
        "# edited from : https://martin-thoma.com/word-error-rate-calculation/\n",
        "# with Hunt (1990) has proposed the use of a weighted measure of performance where deletion and insertion are both weighted only at 0.5\n",
        "def adapted_wer(r, h):\n",
        "    \"\"\"\n",
        "    r is reference, h is hypothesis\n",
        "    mask non-function words with \"#\" when calculate distance\n",
        "    \"\"\"\n",
        "    # initialisation\n",
        "    import numpy\n",
        "    d = numpy.zeros((len(r)+1)*(len(h)+1)) \n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            inc_sub = 1\n",
        "            inc_ins = 0.2\n",
        "            inc_del = 0.2\n",
        "            # if r[i-1] == \"#\":\n",
        "            #     inc_sub, inc_ins, inc_del = 0, 0.5, 0.5\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + inc_sub\n",
        "                insertion    = d[i][j-1] + inc_ins\n",
        "                deletion     = d[i-1][j] + inc_del\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "\n",
        "    return d[len(r)][len(h)]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikMEHxhSsxLS"
      },
      "source": [
        "\n",
        "\n",
        "def recalculate_avg_wer(selects):\n",
        "    sum_wer = 0 \n",
        "    for select in selects:\n",
        "        selected_1 = select.get(\"selected_1\")\n",
        "        selected_2 = select.get(\"selected_2\")\n",
        "        selected_3 = select.get(\"selected_3\")\n",
        "\n",
        "        sum_wer += (selected_1[4]+selected_2[4] + selected_3[4])/3\n",
        "        # sum_wer += selected_1[4]\n",
        "    return sum_wer/len(selects)\n",
        "\n",
        "def recalculate_wer(selects):\n",
        "    sum_all_wer = 0\n",
        "    for select in selects:\n",
        "        raw_masked_split = select.get('input')\n",
        "\n",
        "        input_idx = select.get(\"input\")[0]\n",
        "        raw_masked_split = idx_entry_map.get(input_idx)[MASK_SPLIT_COL]\n",
        "        sum_select_wer = 0\n",
        "        for i in [\"1\",\"2\", \"3\"]:\n",
        "            select_idx =  select.get(\"selected_\"+i)[0]\n",
        "            selected_masked_split = idx_entry_map.get(select_idx)[MASK_SPLIT_COL]\n",
        "            wer_dist = adapted_wer(raw_masked_split, selected_masked_split)\n",
        "            wer_rate = wer_dist/len(raw_masked_split)\n",
        "            sum_select_wer += wer_rate\n",
        "        avg_wer = sum_select_wer/3\n",
        "        sum_all_wer += avg_wer\n",
        "\n",
        "    return sum_all_wer/len(selects)\n",
        "\n",
        "# for key, selects in wer_result_dict.items():\n",
        "#     print(key, recalculate_avg_wer(selects))\n",
        "\n",
        "# sub =1, ins = 1, del = 1, recover from reloaded data\n",
        "# elmo 0.5042090582545696\n",
        "# use 0.46128061628279626\n",
        "# use_mask 0.6143357564264627\n",
        "# sdae 0.6306218394437425\n",
        "# elmo_mask 0.6856460360211806\n",
        "# w2v 0.6610528727731038\n",
        "# w2v_mask 2.4222398729150205\n",
        "\n",
        "\n",
        "\n",
        "# for key, selects in wer_result_dict.items():\n",
        "#     print(key, recalculate_wer(selects))\n",
        "\n",
        "\n",
        "# sub = 1, ins = 0.5, del = 0.5\n",
        "# elmo 0.5402552829417606\n",
        "# use 0.6391554046335199\n",
        "# use_mask 0.5448933146043207\n",
        "# sdae 0.5004732376210101\n",
        "# elmo_mask 0.48619971794627437\n",
        "# w2v 0.905774806031501\n",
        "# w2v_mask 0.920564334921754\n",
        "\n",
        "# for key, selects in wer_result_dict.items():\n",
        "    # print(key, recalculate_wer(selects))\n",
        "\n",
        "    \n",
        "# sub = 1, ins = 0.1, del = 0.1\n",
        "# elmo 0.1442342006113179\n",
        "# use 0.17527708765817168\n",
        "# use_mask 0.1453520523694472\n",
        "# sdae 0.1226655331718089\n",
        "# elmo_mask 0.12327695719821678\n",
        "# w2v 0.29092100592104553\n",
        "# w2v_mask 0.29132159684799863\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abIa3YnRMJ4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5b9c6102-fa13-4531-b84c-e68ab40ef5e1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elmo 0.2435208530816369\n",
            "use 0.29149197389850523\n",
            "use_mask 0.24572459543023525\n",
            "sdae 0.21725605188418745\n",
            "elmo_mask 0.21424600794927992\n",
            "w2v 0.4447332373107591\n",
            "w2v_mask 0.4487530993702097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqVGfYvfS2v2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "dd9ee55e-7503-476a-8a8b-84a24bb92430"
      },
      "source": [
        "tmp_exm_idx = 6327\n",
        "print(wer_result_dict.get(\"elmo\")[tmp_exm_idx])\n",
        "print(wer_result_dict.get(\"elmo_mask\")[tmp_exm_idx])\n",
        "print(wer_result_dict.get(\"use_mask\")[tmp_exm_idx])\n",
        "print(wer_result_dict.get(\"sdae\")[tmp_exm_idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input': (6327, '3005', '\"It could be a little choppy. It could be uneven. And it\\'s going to take awhile.\"'), 'selected_1': (726, '3248', \"It's possible, it's just going to look ugly unless you want to install the rest of KDE, that's all.\", 0.14808011054992676, 0.42857142857142855), 'selected_2': (1513, '6326', 'Treasury Secretary Timothy Geithner says the economic recovery \"could be a little choppy\" and it\\'s going to take a while.', 0.14885741472244263, 0.4880952380952381), 'selected_3': (3321, '6130', '\"They\\'re just so beneficial right now. It\\'s a luxury right now. It takes so much pressure off us.\"', 0.1510900855064392, 0.5833333333333334), 'avg_wer': 0.5}\n",
            "{'input': (6327, '3005', '\"It could be a little choppy. It could be uneven. And it\\'s going to take awhile.\"'), 'selected_1': (5369, '3006', \"It could be done to a change of frequency, but it should report it...( thing that doesn't happens).\", 0.05625051259994507, 0.5), 'selected_2': (1097, '639', '\"As awful as this attack was,\" Leonhardy said, \"just maybe it can represent a teachable moment. If people pay attention.\"', 0.0688977837562561, 0.6304347826086957), 'selected_3': (1307, '3101', '\"It is important to have an honest and open debate about drugs,\" Vaz said.', 0.0693090558052063, 0.45652173913043476), 'avg_wer': 0.5289855072463768}\n",
            "{'input': (6327, '3005', '\"It could be a little choppy. It could be uneven. And it\\'s going to take awhile.\"'), 'selected_1': (1513, '6326', 'Treasury Secretary Timothy Geithner says the economic recovery \"could be a little choppy\" and it\\'s going to take a while.', 0.2029072642326355, 0.575), 'selected_2': (5127, '3329', 'It would be nice if this functionality could be incorporated to the way linux handles unmounting external drives powered by the usb.', 0.2238752841949463, 0.575), 'selected_3': (1337, '5642', '\"The old school would say that freshmen could be seen but shouldn\\'t be heard,\" Kirk said in a brief interview.', 0.2664601802825928, 0.5), 'avg_wer': 0.5499999999999999}\n",
            "{'input': (6327, '3005', '\"It could be a little choppy. It could be uneven. And it\\'s going to take awhile.\"'), 'selected_1': (4150, '2346', '\"I don\\'t need to tell you the honor that would be.\"', 0.00410948409439682, 0.6), 'selected_2': (2734, '6246', '\"This was not a gang thing. It was just a mob that got out of control. It was the older ones who led it all.\"', 0.0041401467882825616, 0.65), 'selected_3': (4498, '3328', '\"It would be difficult to detain another person while removing their clothes and one\\'s own clothing,\" Mr Cavanagh said.', 0.004275361048965198, 0.475), 'avg_wer': 0.5750000000000001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh1A0wHJ75sY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "199ec53a-a83c-493e-86d3-7f64882e15be"
      },
      "source": [
        "# ========================================\n",
        "# generate results_dist.csv\n",
        "\n",
        "import csv\n",
        "\n",
        "with open(\"analysis/results_dist.csv\", 'w', newline='') as myfile:\n",
        "     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "     my_header = [\"input_idx\", \"input_sent_id\", \"input_sent\",\n",
        "                  \"elmo_idx\", \"elmo_sent_id\", \"elmo_sent\",\"elmo_dist\",\n",
        "                   \"emlo_mask_idx\", \"emlo_mask_sent_id\", \"emlo_mask_sent\",\"emlo_mask_dist\",\n",
        "                   \"use_idx\", \"use_sent_id\", \"use_sent\",\"use_dist\",\n",
        "                   \"use_mask_idx\", \"use_mask_sent_id\", \"use_mask_sent\",\"use_mask_dist\",\n",
        "                  \"sdae_idx\", \"sdae_sent_id\", \"sdae_sent\",\"sdae_dist\",\n",
        "                  \"num_candidate\"\n",
        "                  ]\n",
        "     wr.writerow(my_header)\n",
        "     my_list = []\n",
        "     for idx in range(0,6328):\n",
        "        my_item = []\n",
        "        input_sample = wer_result_dict.get(\"elmo\")[idx].get(\"input\")\n",
        "        my_item.append(input_sample[0])\n",
        "        my_item.append(input_sample[1])\n",
        "        my_item.append(input_sample[2])\n",
        "        candidate_set = set()\n",
        "        for item_key in [\"elmo\",\"elmo_mask\",\"use\",\"use_mask\",\"sdae\"]:\n",
        "            this_top = wer_result_dict.get(item_key)[idx].get(\"selected_1\")\n",
        "            my_item.append(this_top[0])\n",
        "            my_item.append(this_top[1])\n",
        "            my_item.append(this_top[2])\n",
        "            my_item.append(this_top[3])\n",
        "            candidate_set.add(this_top[0])\n",
        "        num_candidate = len(candidate_set)\n",
        "        my_item.append(num_candidate)\n",
        "        my_list.append(my_item)\n",
        "        wr.writerow(my_item)\n",
        "\n",
        "pickle_save(\"analysis/results_dist.pkl\", my_list)\n",
        "\n",
        "print(len(my_list))\n",
        "print(my_list[2])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6328\n",
            "[2, '588', 'A reading above 50 indicates an expansion.', 1833, '4435', 'Readings greater than 50 signal expansion.', 0.10464566946029663, 1251, '130', 'A couple of Marriotts just opened.', 0.048340022563934326, 1833, '4435', 'Readings greater than 50 signal expansion.', 0.34535109996795654, 5776, '6035', \"The video, sadly, winks out right as the expert is being brought in to explain Skinner's research.\", 0.1761012077331543, 784, '5181', 'The authors report no financial disclosures.', 0.0009925732658990771, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyCOGSoaGHx0"
      },
      "source": [
        "# ========================================\n",
        "# reformat for human evaluation from mylist\n",
        "\n",
        "my_list = pickle_load(\"analysis/results_dist.pkl\")\n",
        "\n",
        "candidates = []\n",
        "# input_idx_list = [0,2,3,8,30,37,38,40,42,47,52,56,58,62,66,69,71,83,90,93]\n",
        "# input_idx_list = [99,101,110,116,118,122,124,129,135,137,147,159,160,168,184,187,197,209,211,216]\n",
        "input_idx_list = [218,231,235,238,241,258,285,303,305,322,329,330,333,335,336,352,357,366,376,379]\n",
        "                  \n",
        "for idx in input_idx_list:\n",
        "    item = my_list[idx]\n",
        "    # candidate_set = set()\n",
        "    # candidate_set.add(item[5])\n",
        "    # candidate_set.add(item[9])\n",
        "    # candidate_set.add(item[13])\n",
        "    # candidate_set.add(item[17])\n",
        "    # candidate_set.add(item[21])\n",
        "        \n",
        "    candidate_dict = {}\n",
        "    candidate_dict[\"input\"] = item[2]\n",
        "    candidate_dict[item[3]] = item[5]\n",
        "    candidate_dict[item[7]] = item[9]\n",
        "    candidate_dict[item[11]] = item[13]\n",
        "    candidate_dict[item[15]] = item[17]\n",
        "    candidate_dict[item[19]] = item[21]\n",
        "\n",
        "    if len(candidate_dict) != 5:\n",
        "        print(\"wrong\", idx, len(candidate_dict))\n",
        "    candidates.append(candidate_dict)\n",
        "\n",
        "\n",
        "\n",
        "with open(\"analysis/human_eval_c4_f41-60.csv\", 'w', newline='') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    # wr.writerow([\"input\",\"selected_1\", \"selected_2\", \"selected_3\", \"selected_4\"])\n",
        "    wr.writerow([\"input_candidates\", \"rater_selected\"])\n",
        "    for cand in candidates:\n",
        "        formatted = \"input: \" + cand.get(\"input\") + \"\\n\"\n",
        "        for key, value in cand.items():\n",
        "            if key != \"input\":\n",
        "                formatted += str(key) + \". \" + value + \"\\n\"\n",
        "        wr.writerow([formatted, \"\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0gaMDRDvBiN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bffbac5d-0c16-4f05-9afc-b44c007c283c"
      },
      "source": [
        "# ========================================\n",
        "# examine raters selections\n",
        "# ========================================\n",
        "\n",
        "# reader = csv.reader(open(\"analysis/human_eval_results_v0.csv\", newline='', encoding='utf-8'), delimiter=',',\n",
        "#                         quotechar='\"')\n",
        "my_list = pickle_load(\"analysis/results_dist.pkl\")\n",
        "\n",
        "reader = csv.reader(open(\"analysis/human_eval_results_f60.csv\", newline='', encoding='utf-8'), delimiter=',',\n",
        "                        quotechar='\"')\n",
        "row_cnt = 0\n",
        "\n",
        "key_idxcol_map = {\"elmo\": 3, \"elmo_mask\": 7, \"use\": 11, \"use_mask\": 15, \"sdae\": 19}\n",
        "\n",
        "match_list = []\n",
        "match_cnt = {\"elmo\":0, \"elmo_mask\": 0, \"use\": 0, \"use_mask\": 0, \"sdae\": 0}\n",
        "\n",
        "selection_dict = {\n",
        "    \"rater1\": [],\n",
        "    \"rater2\": [],\n",
        "    \"elmo\": [],\n",
        "    \"elmo_mask\": [],\n",
        "    \"use\": [],\n",
        "    \"use_mask\": [],\n",
        "    \"sdae\": [],\n",
        "    \"reference\": []\n",
        "}\n",
        "\n",
        "try:\n",
        "    for row in reader:\n",
        "        row_cnt += 1\n",
        "        if row_cnt == 1:\n",
        "            continue\n",
        "        \n",
        "        input_idx = int(row[0])\n",
        "        rater1_idx = int(row[1])\n",
        "        rater2_idx = int(row[2])\n",
        "\n",
        "        selection_dict.get(\"rater1\").append(rater1_idx)\n",
        "        selection_dict.get(\"rater2\").append(rater2_idx)\n",
        "        selection_dict.get(\"reference\").append(set([rater1_idx,rater2_idx]))\n",
        "\n",
        "        record = my_list[input_idx]\n",
        "        match = []\n",
        "        for key,value in key_idxcol_map.items():\n",
        "            selected_idx = int(record[value])\n",
        "            selection_dict.get(key).append(selected_idx)\n",
        "            if selected_idx == rater1_idx or selected_idx == rater2_idx:\n",
        "                match.append(key)\n",
        "                match_cnt[key] = match_cnt[key] + 1\n",
        "\n",
        "        # print(match)\n",
        "\n",
        "        match_list.append(match)\n",
        "\n",
        "except Exception as ex:\n",
        "    sys.stderr.write('Exception\\n')\n",
        "    extype, exvalue, extrace = sys.exc_info()\n",
        "    traceback.print_exception(extype, exvalue, extrace)\n",
        "\n",
        "# print(match_list)\n",
        "print(match_cnt)\n",
        "print([(key, value/40) for key, value in match_cnt.items()])\n",
        "# print(selection_dict)\n",
        "# print(selection_dict.get(\"rater1\"))\n",
        "# print(selection_dict.get(\"elmo\"))\n",
        "\n",
        "# f40:\n",
        "# {'elmo': 10, 'elmo_mask': 14, 'use': 8, 'use_mask': 5, 'sdae': 25}\n",
        "# [('elmo', 0.25), ('elmo_mask', 0.35), ('use', 0.2), ('use_mask', 0.125), ('sdae', 0.625)]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'elmo': 17, 'elmo_mask': 23, 'use': 14, 'use_mask': 7, 'sdae': 35}\n",
            "[('elmo', 0.425), ('elmo_mask', 0.575), ('use', 0.35), ('use_mask', 0.175), ('sdae', 0.875)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp-Ysi5dumEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "bd443871-6b1c-4d06-fb06-7a6062445846"
      },
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "def mcnemar_pvalue(list1,list2,truth_list):\n",
        "    cnt_yes_yes = 0\n",
        "    cnt_yes_no = 0\n",
        "    cnt_no_yes = 0\n",
        "    cnt_no_no = 0\n",
        "\n",
        "    yes_yes, yes_no, no_yes, no_no = [], [], [], []\n",
        "\n",
        "    # calculate contingency table\n",
        "    # format: contingency_table = [[cnt_yes_yes, cnt_yes_no],[cnt_no_yes, cnt_no_no]]\n",
        "\n",
        "    for i in range(len(list1)):\n",
        "        truth = truth_list[i]\n",
        "        label_1 = list1[i]\n",
        "        label_2 = list2[i]\n",
        "\n",
        "        if truth_list is not None:\n",
        "            # --------------------------------\n",
        "            # compute correctness\n",
        "            if label_1 in truth and label_2 in truth:\n",
        "                cnt_yes_yes += 1      \n",
        "            elif label_1 in truth and label_2 not in truth:\n",
        "                cnt_yes_no += 1\n",
        "            elif label_1 not in truth and label_2 in truth:\n",
        "                cnt_no_yes += 1\n",
        "            elif label_1 not in truth and label_2 not in truth:\n",
        "                cnt_no_no += 1\n",
        "            else:\n",
        "                print(\"correctness comparison error\")\n",
        "        else:\n",
        "            # --------------------------------\n",
        "            # compute agreement\n",
        "            if label_1 == 1 and label_2 == 1:\n",
        "                cnt_yes_yes += 1  \n",
        "                yes_yes.append(i)    \n",
        "            elif label_1 == 1 and label_2 != 1:\n",
        "                cnt_yes_no += 1\n",
        "                yes_no.append(i)\n",
        "            elif label_1 != 1 and label_2 == 1:\n",
        "                cnt_no_yes += 1\n",
        "                no_yes.append(i)\n",
        "            elif label_1 != 1 and label_2 != 1:\n",
        "                cnt_no_no += 1\n",
        "                no_no.append(i)\n",
        "            else:\n",
        "                print(\"agreement comparison error\")\n",
        "            \n",
        "    contingency_table = [[cnt_yes_yes, cnt_yes_no],[cnt_no_yes, cnt_no_no]]\n",
        "    print(\"contingency table: \", contingency_table)\n",
        "\n",
        "    # calculate mcnemar test\n",
        "    result = mcnemar(contingency_table, exact=True)\n",
        "\n",
        "    # summarize the finding\n",
        "    print('statistic=%.3f, p-value=%.2E' % (result.statistic, result.pvalue))\n",
        "\n",
        "    # interpret the p-value\n",
        "    alpha = 0.05\n",
        "\n",
        "    if result.pvalue > alpha:\n",
        "        print('Same proportions of errors (fail to reject H0)')\n",
        "    else:\n",
        "        print('Different proportions of errors (reject H0)')\n",
        "\n",
        "    return result\n",
        "\n",
        "print(\"------ elmo vs. elmo mask:\")\n",
        "p = mcnemar_pvalue(selection_dict.get(\"elmo\"), selection_dict.get(\"elmo_mask\"), selection_dict.get(\"reference\"))\n",
        "# print(p)\n",
        "\n",
        "print(\"------ use vs. use mask:\")\n",
        "p = mcnemar_pvalue(selection_dict.get(\"use\"), selection_dict.get(\"use_mask\"), selection_dict.get(\"reference\"))\n",
        "# print(p)\n",
        "\n",
        "\n",
        "print(\"------ sdae vs. elmo:\")\n",
        "p = mcnemar_pvalue(selection_dict.get(\"sdae\"), selection_dict.get(\"elmo\"), selection_dict.get(\"reference\"))\n",
        "# print(p)\n",
        "\n",
        "\n",
        "print(\"------ sdae vs. use:\")\n",
        "p = mcnemar_pvalue(selection_dict.get(\"sdae\"), selection_dict.get(\"use\"), selection_dict.get(\"reference\"))\n",
        "# print(p)\n",
        "\n",
        "print(\"------ sdae vs. elmo mask:\")\n",
        "p = mcnemar_pvalue(selection_dict.get(\"sdae\"), selection_dict.get(\"elmo_mask\"), selection_dict.get(\"reference\"))\n",
        "# print(p)\n",
        "\n",
        "\n",
        "print(\"------ sdae vs. use mask:\")\n",
        "p = mcnemar_pvalue(selection_dict.get(\"sdae\"), selection_dict.get(\"use_mask\"), selection_dict.get(\"reference\"))\n",
        "# print(p)\n",
        "\n",
        "# ------ elmo vs. elmo mask:\n",
        "# contingency table:  [[3, 4], [4, 9]]\n",
        "# statistic=4.000, p-value=1.00E+00\n",
        "# Same proportions of errors (fail to reject H0)\n",
        "# ------ use vs. use mask:\n",
        "# contingency table:  [[0, 3], [1, 16]]\n",
        "# statistic=1.000, p-value=6.25E-01\n",
        "# Same proportions of errors (fail to reject H0)\n",
        "# ------ sdae vs. elmo:\n",
        "# contingency table:  [[2, 11], [5, 2]]\n",
        "# statistic=5.000, p-value=2.10E-01\n",
        "# Same proportions of errors (fail to reject H0)\n",
        "# ------ sdae vs. use:\n",
        "# contingency table:  [[1, 12], [2, 5]]\n",
        "# statistic=2.000, p-value=1.29E-02\n",
        "# Different proportions of errors (reject H0)\n",
        "# ------ sdae vs. elmo mask:\n",
        "# contingency table:  [[2, 11], [5, 2]]\n",
        "# statistic=5.000, p-value=2.10E-01\n",
        "# Same proportions of errors (fail to reject H0)\n",
        "# ------ sdae vs. use mask:\n",
        "# contingency table:  [[0, 13], [1, 6]]\n",
        "# statistic=1.000, p-value=1.83E-03\n",
        "# Different proportions of errors (reject H0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ elmo vs. elmo mask:\n",
            "contingency table:  [[4, 6], [10, 20]]\n",
            "statistic=6.000, p-value=4.54E-01\n",
            "Same proportions of errors (fail to reject H0)\n",
            "------ use vs. use mask:\n",
            "contingency table:  [[1, 7], [4, 28]]\n",
            "statistic=4.000, p-value=5.49E-01\n",
            "Same proportions of errors (fail to reject H0)\n",
            "------ sdae vs. elmo:\n",
            "contingency table:  [[3, 22], [7, 8]]\n",
            "statistic=7.000, p-value=8.13E-03\n",
            "Different proportions of errors (reject H0)\n",
            "------ sdae vs. use:\n",
            "contingency table:  [[2, 23], [6, 9]]\n",
            "statistic=6.000, p-value=2.32E-03\n",
            "Different proportions of errors (reject H0)\n",
            "------ sdae vs. elmo mask:\n",
            "contingency table:  [[5, 20], [9, 6]]\n",
            "statistic=9.000, p-value=6.14E-02\n",
            "Same proportions of errors (fail to reject H0)\n",
            "------ sdae vs. use mask:\n",
            "contingency table:  [[2, 23], [3, 12]]\n",
            "statistic=3.000, p-value=8.80E-05\n",
            "Different proportions of errors (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBRXuWOXijYx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ae77439-25eb-4a8e-effb-ddc8261c9aa4"
      },
      "source": [
        "# ========================================\n",
        "# examine raters agreement\n",
        "# ========================================\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "\n",
        "cohen_kappa_score(selection_dict.get(\"rater1\"), selection_dict.get(\"rater2\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7804054054054055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwhvws5B2lA1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e3d4f2de-29fa-415a-cc0c-d14ee107ef9a"
      },
      "source": [
        "# mcnemar test\n",
        "\n",
        "# Example of calculating the mcnemar test\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "cnt_yes_yes = 0\n",
        "cnt_yes_no = 0\n",
        "cnt_no_yes = 0\n",
        "cnt_no_no = 0\n",
        "\n",
        "yes_yes, yes_no, no_yes, no_no = [], [], [], []\n",
        "\n",
        "# calculate contingency table\n",
        "# format: contingency_table = [[cnt_yes_yes, cnt_yes_no],[cnt_no_yes, cnt_no_no]]\n",
        "\n",
        "for i, label in enumerate(test_labels):\n",
        "    truth = int(label)\n",
        "    elmo_label = int(use_predict_labels[i])\n",
        "    sdae_label = int(sdae_predict_labels[i])\n",
        "    # print(elmo_label, sdae_label)\n",
        "    # --------------------------------\n",
        "    # compute correctness\n",
        "    # if elmo_label == truth and sdae_label == truth:\n",
        "    #     cnt_yes_yes += 1      \n",
        "    # elif elmo_label == truth and sdae_label != truth:\n",
        "    #     cnt_yes_no += 1\n",
        "    # elif elmo_label != truth and sdae_label == truth:\n",
        "    #     cnt_no_yes += 1\n",
        "    # elif elmo_label != truth and sdae_label != truth:\n",
        "    #     cnt_no_no += 1\n",
        "    # else:\n",
        "    #     print(\"Comparison error\")\n",
        "    \n",
        "    # --------------------------------\n",
        "    # compute agreement\n",
        "    if elmo_label == 1 and sdae_label == 1:\n",
        "        cnt_yes_yes += 1  \n",
        "        yes_yes.append(i)    \n",
        "    elif elmo_label == 1 and sdae_label != 1:\n",
        "        cnt_yes_no += 1\n",
        "        yes_no.append(i)\n",
        "    elif elmo_label != 1 and sdae_label == 1:\n",
        "        cnt_no_yes += 1\n",
        "        no_yes.append(i)\n",
        "    elif elmo_label != 1 and sdae_label != 1:\n",
        "        cnt_no_no += 1\n",
        "        no_no.append(i)\n",
        "    else:\n",
        "        print(\"Comparison error\")\n",
        "        \n",
        "contingency_table = [[cnt_yes_yes, cnt_yes_no],[cnt_no_yes, cnt_no_no]]\n",
        "print(\"contingency table: \", contingency_table)\n",
        "\n",
        "# calculate mcnemar test\n",
        "result = mcnemar(contingency_table, exact=True)\n",
        "\n",
        "# summarize the finding\n",
        "print('statistic=%.3f, p-value=%.2E' % (result.statistic, result.pvalue))\n",
        "\n",
        "# interpret the p-value\n",
        "alpha = 0.05\n",
        "\n",
        "if result.pvalue > alpha:\n",
        "\tprint('Same proportions of errors (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different proportions of errors (reject H0)')\n",
        "\n",
        "\n",
        "print(\"Elmo yes SDAE no:\", yes_no)\n",
        "print(\"Elmo no Sdae yes:\", no_yes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "contingency table:  [[89, 238], [43, 334]]\n",
            "statistic=43.000, p-value=6.90E-34\n",
            "Different proportions of errors (reject H0)\n",
            "Elmo yes SDAE no: [1, 2, 3, 7, 15, 16, 23, 24, 30, 32, 34, 38, 39, 41, 43, 44, 48, 51, 55, 58, 63, 64, 67, 69, 71, 75, 79, 81, 82, 83, 86, 95, 96, 98, 100, 106, 107, 109, 110, 113, 115, 116, 117, 123, 124, 128, 130, 131, 135, 145, 146, 147, 148, 150, 153, 155, 156, 159, 160, 162, 164, 166, 169, 172, 173, 175, 180, 189, 192, 197, 198, 204, 205, 206, 210, 211, 214, 223, 227, 228, 231, 232, 235, 241, 243, 244, 249, 251, 253, 256, 257, 259, 260, 264, 269, 270, 276, 277, 278, 288, 289, 291, 292, 295, 301, 303, 304, 305, 310, 317, 321, 325, 331, 333, 334, 336, 337, 339, 342, 346, 347, 349, 350, 354, 357, 363, 366, 367, 372, 373, 378, 379, 380, 381, 382, 384, 389, 390, 391, 396, 398, 400, 401, 403, 405, 407, 408, 413, 416, 417, 418, 419, 421, 426, 427, 428, 429, 430, 432, 433, 434, 435, 441, 443, 445, 451, 459, 463, 466, 471, 473, 474, 475, 479, 482, 485, 486, 487, 488, 492, 498, 499, 505, 513, 514, 516, 517, 520, 523, 537, 538, 543, 548, 550, 551, 552, 559, 561, 565, 568, 571, 583, 584, 586, 587, 588, 590, 593, 597, 610, 618, 622, 623, 628, 629, 630, 635, 641, 645, 650, 655, 657, 658, 661, 662, 664, 665, 667, 668, 670, 672, 675, 679, 680, 682, 685, 686, 693]\n",
            "Elmo no Sdae yes: [14, 21, 40, 46, 50, 78, 94, 104, 112, 151, 152, 157, 158, 168, 176, 185, 196, 199, 222, 224, 258, 265, 275, 324, 358, 388, 438, 439, 456, 496, 546, 562, 579, 580, 605, 614, 639, 651, 656, 687, 689, 692, 700]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5rlZqj9Z51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6bea069c-72cc-4b70-db56-40316885ddbe"
      },
      "source": [
        "print(np.mean([0.7137931 , 0.73231466, 0.76816239]))\n",
        "print(np.mean([0.72485365, 0.72      , 0.74170124]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7380900499999999\n",
            "0.72885163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVLTMzpKbIYU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "3c7e466c-8148-4d08-bad0-32624f5e7a5d"
      },
      "source": [
        "# uni-gram\n",
        "print(\"uni-gram\")\n",
        "# raw d-max (6102)\n",
        "print(np.mean([0.73571429, 0.72142857, 0.73571429, 0.75      , 0.74193548]))\n",
        "# raw d-1000\n",
        "print(np.mean([0.71785714, 0.69642857, 0.72142857, 0.68571429, 0.72043011]))\n",
        "# mask\n",
        "print(np.mean([0.73928571, 0.72857143, 0.72142857, 0.73214286, 0.74193548]))\n",
        "\n",
        "# bi-gram\n",
        "print(\"bi-gram\")\n",
        "# raw\n",
        "print(np.mean([0.63928571, 0.71428571, 0.65714286, 0.61785714, 0.68100358]))\n",
        "# mask\n",
        "print(np.mean([0.71428571, 0.75714286, 0.71428571, 0.69642857, 0.74551971]))\n",
        "\n",
        "# -----------------------------\n",
        "\n",
        "print(\"when mask all content words for learning embedding:\")\n",
        "# word-emb-d: 300, learned-d: 100\n",
        "print(np.mean([0.69285714, 0.76071429, 0.725     , 0.71785714, 0.6953405 ]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uni-gram\n",
            "0.736958526\n",
            "0.708371736\n",
            "0.73267281\n",
            "bi-gram\n",
            "0.661915\n",
            "0.725532512\n",
            "when mask all content words for learning embedding:\n",
            "0.718353814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyVzX2W9c5WM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "5d36b4fb-0f5f-4f03-d9ff-5a7649f36f2d"
      },
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        " \n",
        "# import tensorflow_hub as hub\n",
        "# import tensorflow as tf\n",
        " \n",
        "# elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        " \n",
        " \n",
        "# def elmo_vectors(x): \n",
        "#   embeddings=elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "  \n",
        "#   with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "#     sess.run(tf.tables_initializer())\n",
        "#     # return average of ELMo features\n",
        "#     return sess.run(tf.reduce_mean(embeddings,1))\n",
        "\n",
        "\n",
        "corpus=['\"The root of this is dispossession and deprivation,\" said Ramachandra Guha, a prominent historian based in Bangalore.',\n",
        "'The symptoms were pretty much the same as what you describe; in fact, in particular, it was the alt key that had problems.',\n",
        "'''And she's \"learned what's important in life?\"''',\n",
        "'''Emanuel continues to believe that oceans in a warming world will produce stronger storms, because the trend over the last 30 years in the Western North Pacific and Atlantic basins is upward.''',\n",
        "'''After another crushing loss, Washington State coach Paul Wulff took away the almost bowl-like atmosphere as at least one positive.''',\n",
        "'''In its internal announcement, I.B.M. said Mr. Moffat was being replaced by Rodney C. Adkins, a rising younger executive, who becomes a senior vice president of the systems and technology group.'''\n",
        "]\n",
        "\n",
        "elmo_embeddings=[]\n",
        "\n",
        "for i in range(len(corpus)):\n",
        "    print (corpus[i])\n",
        "    elmo_embeddings.append(elmo_vectors([corpus[i]])[0])\n",
        "\n",
        "print (elmo_embeddings)\n",
        "print(cosine_similarity(elmo_embeddings, elmo_embeddings))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"The root of this is dispossession and deprivation,\" said Ramachandra Guha, a prominent historian based in Bangalore.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The symptoms were pretty much the same as what you describe; in fact, in particular, it was the alt key that had problems.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "And she's \"learned what's important in life?\"\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Emanuel continues to believe that oceans in a warming world will produce stronger storms, because the trend over the last 30 years in the Western North Pacific and Atlantic basins is upward.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After another crushing loss, Washington State coach Paul Wulff took away the almost bowl-like atmosphere as at least one positive.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "In its internal announcement, I.B.M. said Mr. Moffat was being replaced by Rodney C. Adkins, a rising younger executive, who becomes a senior vice president of the systems and technology group.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[array([-0.3644273 , -0.35249865,  0.13963749, ..., -0.40541363,\n",
            "        0.28308302, -0.04877667], dtype=float32), array([ 0.01186131,  0.35947883, -0.21745291, ..., -0.02570024,\n",
            "        0.29493195,  0.1771647 ], dtype=float32), array([-0.00352885, -0.12127738,  0.34970155, ..., -0.17586514,\n",
            "        0.42037353,  0.12657686], dtype=float32), array([ 0.15438657,  0.09934765,  0.1578552 , ..., -0.02052657,\n",
            "        0.63652134,  0.18594106], dtype=float32), array([-0.10641526, -0.19809897,  0.05857019, ..., -0.13659824,\n",
            "        0.03297533,  0.23494276], dtype=float32), array([-0.13015747, -0.0990373 , -0.10758118, ..., -0.03415059,\n",
            "       -0.02957566,  0.03130121], dtype=float32)]\n",
            "[[1.0000001  0.4095855  0.50060546 0.38853735 0.40622115 0.41964838]\n",
            " [0.4095855  0.9999999  0.5676453  0.4504942  0.46586353 0.31911105]\n",
            " [0.50060546 0.5676453  0.9999998  0.4529013  0.44194466 0.30684596]\n",
            " [0.38853735 0.4504942  0.4529013  0.99999964 0.3872245  0.32934457]\n",
            " [0.40622115 0.46586353 0.44194466 0.3872245  1.0000002  0.40491498]\n",
            " [0.41964838 0.31911105 0.30684596 0.32934457 0.40491498 0.9999999 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFGHpsdeH_2k"
      },
      "source": [
        "# original wer: https://martin-thoma.com/word-error-rate-calculation/\n",
        "def wer(r, h):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance.\n",
        "\n",
        "    Works only for iterables up to 254 elements (uint8).\n",
        "    O(nm) time ans space complexity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    r : list\n",
        "    h : list\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
        "    1\n",
        "    >>> wer(\"who is there\".split(), \"\".split())\n",
        "    3\n",
        "    >>> wer(\"\".split(), \"who is there\".split())\n",
        "    3\n",
        "    \"\"\"\n",
        "    # initialisation\n",
        "    import numpy\n",
        "    d = numpy.zeros((len(r)+1)*(len(h)+1), dtype=numpy.uint8)\n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + 1\n",
        "                insertion    = d[i][j-1] + 1\n",
        "                deletion     = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "\n",
        "    return d[len(r)][len(h)]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}